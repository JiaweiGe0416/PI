{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06d1906d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from all_functions import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a2b5620b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('X_transformed_top_5.CSV')\n",
    "X = X.to_numpy()[:,1:]\n",
    "Y = pd.read_csv('Transformed_Y.CSV')\n",
    "Y = Y.to_numpy()[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b504abeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_axis = \"UNRATE\"\n",
    "Y = Y[:,0].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bd6c390d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.1],\n",
       "       [-0.2],\n",
       "       [ 0. ],\n",
       "       [-0.3],\n",
       "       [ 0.2],\n",
       "       [ 0.3],\n",
       "       [ 0.2],\n",
       "       [ 0.1],\n",
       "       [ 0.3],\n",
       "       [ 0.1],\n",
       "       [ 0.2],\n",
       "       [ 0.3],\n",
       "       [ 0.3],\n",
       "       [ 0.4],\n",
       "       [ 0. ],\n",
       "       [-0.4],\n",
       "       [ 0. ],\n",
       "       [-0.1],\n",
       "       [-0.1],\n",
       "       [-0.1],\n",
       "       [ 0. ],\n",
       "       [-0.7],\n",
       "       [ 0.1],\n",
       "       [-0.3],\n",
       "       [-0.4],\n",
       "       [-0.3],\n",
       "       [-0.2],\n",
       "       [-0.3],\n",
       "       [-0.2],\n",
       "       [ 0. ],\n",
       "       [-0.1],\n",
       "       [-0.3],\n",
       "       [-0.2],\n",
       "       [ 0.3],\n",
       "       [ 0. ],\n",
       "       [-0.2],\n",
       "       [-0.2],\n",
       "       [ 0.1],\n",
       "       [ 0. ],\n",
       "       [-0.1],\n",
       "       [ 0. ],\n",
       "       [ 0.1],\n",
       "       [-0.1],\n",
       "       [ 0.2],\n",
       "       [ 0. ],\n",
       "       [-0.3],\n",
       "       [ 0. ],\n",
       "       [ 0. ],\n",
       "       [-0.1],\n",
       "       [ 0. ],\n",
       "       [-0.3],\n",
       "       [ 0.5],\n",
       "       [ 0. ],\n",
       "       [-0.1],\n",
       "       [ 0.1],\n",
       "       [ 0. ],\n",
       "       [-0.2],\n",
       "       [-0.1],\n",
       "       [ 0.1],\n",
       "       [ 0. ],\n",
       "       [-0.1],\n",
       "       [-0.3],\n",
       "       [ 0. ],\n",
       "       [ 0. ],\n",
       "       [ 0. ],\n",
       "       [-0.3],\n",
       "       [ 0. ],\n",
       "       [-0.1],\n",
       "       [-0.1],\n",
       "       [-0.1],\n",
       "       [-0.1],\n",
       "       [ 0.1],\n",
       "       [-0.2],\n",
       "       [-0.1],\n",
       "       [ 0. ],\n",
       "       [ 0. ],\n",
       "       [ 0. ],\n",
       "       [-0.3],\n",
       "       [ 0.2],\n",
       "       [-0.2],\n",
       "       [ 0. ],\n",
       "       [ 0.2],\n",
       "       [-0.2],\n",
       "       [ 0. ],\n",
       "       [-0.1],\n",
       "       [ 0. ],\n",
       "       [ 0.1],\n",
       "       [-0.2],\n",
       "       [-0.2],\n",
       "       [ 0.2],\n",
       "       [ 0. ],\n",
       "       [ 0.1],\n",
       "       [-0.1],\n",
       "       [ 0. ],\n",
       "       [ 0.1],\n",
       "       [ 0. ],\n",
       "       [ 0.1],\n",
       "       [ 0. ],\n",
       "       [ 0. ],\n",
       "       [-0.1],\n",
       "       [-0.1],\n",
       "       [ 0.2],\n",
       "       [ 0. ],\n",
       "       [-0.2],\n",
       "       [ 0.3],\n",
       "       [ 0.2],\n",
       "       [ 0.2],\n",
       "       [ 0. ],\n",
       "       [ 0.3],\n",
       "       [ 0.1],\n",
       "       [ 0.1],\n",
       "       [ 0.2],\n",
       "       [ 0.2],\n",
       "       [-0.1],\n",
       "       [ 0.2],\n",
       "       [ 0. ],\n",
       "       [-0.1],\n",
       "       [ 0.1],\n",
       "       [ 0. ],\n",
       "       [ 0.1],\n",
       "       [ 0. ],\n",
       "       [ 0.3],\n",
       "       [ 0. ],\n",
       "       [ 0.1],\n",
       "       [ 0. ],\n",
       "       [ 0. ],\n",
       "       [ 0.2],\n",
       "       [ 0.2],\n",
       "       [-0.1],\n",
       "       [-0.1],\n",
       "       [ 0. ],\n",
       "       [-0.3],\n",
       "       [ 0.1],\n",
       "       [ 0. ],\n",
       "       [-0.1],\n",
       "       [-0.2],\n",
       "       [-0.1],\n",
       "       [ 0.1],\n",
       "       [ 0. ],\n",
       "       [-0.1],\n",
       "       [-0.1],\n",
       "       [-0.1],\n",
       "       [-0.1],\n",
       "       [ 0.1],\n",
       "       [-0.2],\n",
       "       [-0.1],\n",
       "       [ 0.1],\n",
       "       [ 0. ],\n",
       "       [-0.1],\n",
       "       [-0.1],\n",
       "       [-0.3],\n",
       "       [ 0. ],\n",
       "       [ 0. ],\n",
       "       [-0.1],\n",
       "       [-0.1],\n",
       "       [-0.1],\n",
       "       [-0.2],\n",
       "       [-0.1],\n",
       "       [ 0.1],\n",
       "       [-0.2],\n",
       "       [ 0. ],\n",
       "       [ 0.4],\n",
       "       [-0.2],\n",
       "       [ 0. ],\n",
       "       [ 0.1],\n",
       "       [ 0. ],\n",
       "       [-0.1],\n",
       "       [-0.1],\n",
       "       [ 0.1],\n",
       "       [ 0. ],\n",
       "       [ 0. ],\n",
       "       [-0.1],\n",
       "       [ 0. ],\n",
       "       [ 0.1],\n",
       "       [ 0. ],\n",
       "       [-0.3],\n",
       "       [ 0.2],\n",
       "       [-0.4],\n",
       "       [ 0.1],\n",
       "       [ 0. ],\n",
       "       [ 0.2],\n",
       "       [ 0. ],\n",
       "       [-0.1],\n",
       "       [-0.1],\n",
       "       [ 0. ],\n",
       "       [-0.1],\n",
       "       [-0.2],\n",
       "       [ 0.1],\n",
       "       [-0.1],\n",
       "       [-0.1],\n",
       "       [ 0.1],\n",
       "       [-0.2],\n",
       "       [-0.1],\n",
       "       [ 0.1],\n",
       "       [-0.1],\n",
       "       [ 0. ],\n",
       "       [ 0.1],\n",
       "       [-0.4],\n",
       "       [ 0.1],\n",
       "       [ 0.1],\n",
       "       [ 0. ],\n",
       "       [ 0. ],\n",
       "       [ 0.1],\n",
       "       [-0.1],\n",
       "       [-0.1],\n",
       "       [ 0. ],\n",
       "       [-0.1],\n",
       "       [ 0.1],\n",
       "       [-0.2],\n",
       "       [ 0.1],\n",
       "       [-0.1],\n",
       "       [ 0.1],\n",
       "       [ 0. ],\n",
       "       [-0.1],\n",
       "       [ 0. ],\n",
       "       [-0.1],\n",
       "       [ 0. ],\n",
       "       [-0.1],\n",
       "       [ 0. ],\n",
       "       [ 0.1],\n",
       "       [-0.1],\n",
       "       [-0.2],\n",
       "       [ 0.2],\n",
       "       [ 0. ],\n",
       "       [ 0. ],\n",
       "       [ 0.1],\n",
       "       [-0.2],\n",
       "       [ 0. ],\n",
       "       [ 0. ],\n",
       "       [ 0. ],\n",
       "       [ 0.3],\n",
       "       [ 0. ],\n",
       "       [ 0.1],\n",
       "       [ 0.1],\n",
       "       [-0.1],\n",
       "       [ 0.2],\n",
       "       [ 0.1],\n",
       "       [ 0.3],\n",
       "       [ 0.1],\n",
       "       [ 0.2],\n",
       "       [ 0.2],\n",
       "       [ 0. ],\n",
       "       [ 0. ],\n",
       "       [ 0. ],\n",
       "       [ 0.2],\n",
       "       [-0.1],\n",
       "       [ 0. ],\n",
       "       [ 0. ],\n",
       "       [-0.1],\n",
       "       [ 0. ],\n",
       "       [ 0. ],\n",
       "       [ 0.2],\n",
       "       [ 0.1],\n",
       "       [-0.2],\n",
       "       [ 0.1],\n",
       "       [ 0. ],\n",
       "       [ 0.1],\n",
       "       [ 0.1],\n",
       "       [ 0.2],\n",
       "       [-0.1],\n",
       "       [-0.1],\n",
       "       [ 0. ],\n",
       "       [-0.1],\n",
       "       [-0.2],\n",
       "       [-0.1],\n",
       "       [ 0. ],\n",
       "       [-0.1],\n",
       "       [ 0.2],\n",
       "       [-0.2],\n",
       "       [ 0. ],\n",
       "       [ 0. ],\n",
       "       [-0.1],\n",
       "       [-0.1],\n",
       "       [ 0. ],\n",
       "       [ 0.1],\n",
       "       [-0.1],\n",
       "       [ 0. ],\n",
       "       [-0.1],\n",
       "       [ 0.1],\n",
       "       [-0.2],\n",
       "       [ 0. ],\n",
       "       [-0.1],\n",
       "       [-0.1],\n",
       "       [ 0. ],\n",
       "       [-0.1],\n",
       "       [ 0.1],\n",
       "       [ 0. ],\n",
       "       [ 0. ],\n",
       "       [-0.1],\n",
       "       [-0.2],\n",
       "       [ 0.1],\n",
       "       [-0.1],\n",
       "       [ 0. ],\n",
       "       [-0.1],\n",
       "       [ 0. ],\n",
       "       [ 0.1],\n",
       "       [ 0. ],\n",
       "       [-0.2],\n",
       "       [-0.1],\n",
       "       [-0.1],\n",
       "       [ 0.2],\n",
       "       [-0.1],\n",
       "       [-0.1],\n",
       "       [ 0.1],\n",
       "       [-0.1],\n",
       "       [ 0.2],\n",
       "       [ 0.1],\n",
       "       [-0.1],\n",
       "       [ 0.1],\n",
       "       [ 0. ],\n",
       "       [ 0. ],\n",
       "       [ 0.3],\n",
       "       [ 0.2],\n",
       "       [ 0.2],\n",
       "       [ 0.3],\n",
       "       [ 0.3],\n",
       "       [ 0.1],\n",
       "       [ 0. ],\n",
       "       [ 0.1],\n",
       "       [ 0.2],\n",
       "       [ 0.2],\n",
       "       [-0.1],\n",
       "       [ 0. ],\n",
       "       [-0.1],\n",
       "       [ 0. ],\n",
       "       [-0.3],\n",
       "       [-0.2],\n",
       "       [ 0. ],\n",
       "       [ 0.1],\n",
       "       [ 0. ],\n",
       "       [-0.1],\n",
       "       [ 0.4],\n",
       "       [-0.1],\n",
       "       [ 0. ],\n",
       "       [ 0.1],\n",
       "       [-0.1],\n",
       "       [ 0.1],\n",
       "       [-0.1],\n",
       "       [ 0. ],\n",
       "       [ 0. ],\n",
       "       [-0.2],\n",
       "       [-0.2],\n",
       "       [-0.1],\n",
       "       [-0.2],\n",
       "       [ 0. ],\n",
       "       [-0.1],\n",
       "       [ 0. ],\n",
       "       [ 0. ],\n",
       "       [ 0. ],\n",
       "       [ 0. ],\n",
       "       [-0.1],\n",
       "       [-0.3],\n",
       "       [ 0. ],\n",
       "       [-0.1],\n",
       "       [ 0.2],\n",
       "       [-0.3],\n",
       "       [-0.2],\n",
       "       [ 0.1],\n",
       "       [-0.1],\n",
       "       [ 0. ],\n",
       "       [-0.2],\n",
       "       [-0.1],\n",
       "       [ 0. ],\n",
       "       [ 0. ],\n",
       "       [-0.3],\n",
       "       [-0.2],\n",
       "       [-0.1],\n",
       "       [ 0.1],\n",
       "       [ 0. ],\n",
       "       [-0.5],\n",
       "       [ 0.1],\n",
       "       [-0.2],\n",
       "       [ 0.1],\n",
       "       [-0.1],\n",
       "       [-0.2],\n",
       "       [-0.2],\n",
       "       [ 0.1],\n",
       "       [-0.2],\n",
       "       [ 0.1],\n",
       "       [-0.2],\n",
       "       [-0.1],\n",
       "       [ 0. ],\n",
       "       [ 0.2],\n",
       "       [-0.3],\n",
       "       [-0.1],\n",
       "       [-0.1],\n",
       "       [-0.1],\n",
       "       [ 0. ],\n",
       "       [ 0.1],\n",
       "       [ 0.1],\n",
       "       [ 0.1],\n",
       "       [ 0.1],\n",
       "       [-0.3],\n",
       "       [ 0.1],\n",
       "       [-0.1],\n",
       "       [ 0.1],\n",
       "       [ 0.1],\n",
       "       [-0.1],\n",
       "       [-0.2],\n",
       "       [ 0. ],\n",
       "       [ 0. ],\n",
       "       [-0.1],\n",
       "       [-0.2],\n",
       "       [ 0. ],\n",
       "       [ 0. ],\n",
       "       [-0.1],\n",
       "       [ 0. ],\n",
       "       [ 0.1],\n",
       "       [-0.1],\n",
       "       [-0.1],\n",
       "       [ 0. ],\n",
       "       [-0.1],\n",
       "       [-0.1],\n",
       "       [ 0.1],\n",
       "       [-0.1],\n",
       "       [ 0. ],\n",
       "       [-0.2],\n",
       "       [ 0.2],\n",
       "       [-0.2],\n",
       "       [ 0. ],\n",
       "       [-0.1],\n",
       "       [ 0.1],\n",
       "       [ 0. ],\n",
       "       [ 0.1],\n",
       "       [ 0.1],\n",
       "       [-0.2],\n",
       "       [ 0. ],\n",
       "       [-0.2],\n",
       "       [ 0. ],\n",
       "       [ 0. ],\n",
       "       [ 0.1],\n",
       "       [ 0. ],\n",
       "       [-0.2],\n",
       "       [ 0.1],\n",
       "       [ 0. ],\n",
       "       [ 0. ],\n",
       "       [-0.1],\n",
       "       [ 0. ],\n",
       "       [-0.5],\n",
       "       [-1. ],\n",
       "       [-0.2],\n",
       "       [ 0. ],\n",
       "       [-0.2],\n",
       "       [ 0.1],\n",
       "       [-0.5],\n",
       "       [-0.2],\n",
       "       [-0.5],\n",
       "       [-0.1],\n",
       "       [-0.4],\n",
       "       [-0.3],\n",
       "       [ 0.1],\n",
       "       [-0.2],\n",
       "       [-0.2],\n",
       "       [ 0. ]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4067bcd3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 453 and the array at index 1 has size 454",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m Data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43mY\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m Q1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mpercentile(Y, \u001b[38;5;241m25\u001b[39m, interpolation \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmidpoint\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mhstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/numpy/core/shape_base.py:345\u001b[0m, in \u001b[0;36mhstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _nx\u001b[38;5;241m.\u001b[39mconcatenate(arrs, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    344\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 453 and the array at index 1 has size 454"
     ]
    }
   ],
   "source": [
    "Data = np.hstack([X,Y])\n",
    "Q1 = np.percentile(Y, 25, interpolation = 'midpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9e084fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FRED_MD_DATA_PREP(index_type): \n",
    "    #X = pd.read_csv('X_pca_top3.CSV')\n",
    "    X = pd.read_csv('X_transformed_top_5.CSV')\n",
    "    X = X.to_numpy()[:,1:]\n",
    "    Y = pd.read_csv('Transformed_Y.CSV')\n",
    "    Y = Y.to_numpy()[:,1:]\n",
    "\n",
    "\n",
    "    # We use X to predict Y = \"UNRATE\"\n",
    "    if index_type == 'UNRATE':\n",
    "        Y_axis = \"UNRATE\"\n",
    "        Y = Y[:,0].reshape(-1,1)\n",
    "    elif index_type == 'HOUST':\n",
    "        Y_axis = \"HOUST\"\n",
    "        Y = Y[:,1].reshape(-1,1)\n",
    "    elif index_type == 'FEDFUNDS':\n",
    "        Y_axis = \"FEDFUNDS\"\n",
    "        Y = Y[:,2].reshape(-1,1)\n",
    "    else: \n",
    "        raise Exception(\"Index type must be one of UNRATE, HOUST or FEDFUNDS!\")\n",
    "\n",
    "    # Remove outliers (w.r.t Y ) using IQR\n",
    "    Data = np.hstack([X,Y])\n",
    "    Q1 = np.percentile(Y, 25, interpolation = 'midpoint')\n",
    "\n",
    "    Q3 = np.percentile(Y, 75, interpolation = 'midpoint')\n",
    "    IQR = Q3 - Q1\n",
    "    upper=Q3+1.5*IQR\n",
    "    upper_array=np.array(Y<=upper)\n",
    "    lower=Q1-1.5*IQR\n",
    "    lower_array=np.array(Y>=lower)\n",
    "    index_keep = upper_array & lower_array\n",
    "    Data = Data[index_keep[:,0].tolist(),:]\n",
    "    print(\"The number of data being removed is \", Y.shape[0]-Data.shape[0])\n",
    "    return Data, Y_axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2b39dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def UTOPIA_FRED_MD_MULTIVARIATE(data, seed = 0, shrink = True):\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(Data)\n",
    "    train_idx = int(Data.shape[0] * 0.8)\n",
    "    train_data, test_data = np.split(Data, [train_idx])\n",
    "    X_pre = train_data[:,:-1]\n",
    "    Y_pre = train_data[:,-1].reshape(-1,1)\n",
    "    X_opt = train_data[:,:-1]\n",
    "    Y_opt = train_data[:,-1].reshape(-1,1)\n",
    "    X_adj = train_data[:,:-1]\n",
    "    Y_adj = train_data[:,-1].reshape(-1,1)\n",
    "    X_t = test_data[:,:-1]\n",
    "    Y_t = test_data[:,-1].reshape(-1,1)\n",
    "\n",
    "\n",
    "    n_pre = len(Y_pre)\n",
    "    n_opt = len(Y_opt)\n",
    "    n_adj = len(Y_adj)\n",
    "    n_t = len(Y_t)\n",
    "\n",
    "    # Obtain mean estimator\n",
    "    known_mean = \"False\"\n",
    "    if known_mean == \"True\":\n",
    "        M_pre = np.zeros(n_pre).reshape(-1,1)\n",
    "        M_opt = np.zeros(n_opt).reshape(-1,1)\n",
    "        M_adj = np.zeros(n_adj).reshape(-1,1)\n",
    "        M_t = np.zeros(n_t).reshape(-1,1)\n",
    "    else:\n",
    "        est_type = \"NN1\"\n",
    "        M_pre, M_opt, M_adj, M_t = mean_est(est_type,X_pre,Y_pre,X_opt,X_adj,X_t)\n",
    "\n",
    "    # Obtain variance estimator\n",
    "    var_opt, var_adj, var_t = var_est(X_pre,Y_pre,M_pre, X_opt,X_adj,X_t,est_type =\"NN1\")\n",
    "\n",
    "\n",
    "    # Obtain quantile estimators\n",
    "    quantile = [0.05,0.35,0.65,0.95]\n",
    "    m1,Q1_opt,Q1_adj,Q1_t = est_quantile(\"NN1\",quantile[0],X_pre,Y_pre,X_opt,X_adj,X_t)\n",
    "    m2,Q2_opt,Q2_adj,Q2_t = est_quantile(\"NN2\",quantile[1],X_pre,Y_pre,X_opt,X_adj,X_t)\n",
    "    m3,Q3_opt,Q3_adj,Q3_t = est_quantile(\"qrf\",quantile[2],X_pre,Y_pre,X_opt,X_adj,X_t)\n",
    "    m4,Q4_opt,Q4_adj,Q4_t = est_quantile(\"gb\",quantile[3],X_pre,Y_pre,X_opt,X_adj,X_t)\n",
    "\n",
    "    # construct estimator matrix\n",
    "    E_opt = np.hstack(((Q1_opt-M_opt)**2, (Q2_opt-M_opt)**2, (Q3_opt-M_opt)**2, (Q4_opt-M_opt)**2, var_opt))\n",
    "    E_opt = E_opt.T\n",
    "    E_adj = np.hstack(((Q1_adj-M_adj)**2, (Q2_adj-M_adj)**2, (Q3_adj-M_adj)**2, (Q4_adj-M_adj)**2, var_adj))\n",
    "    E_adj = E_adj.T\n",
    "    E_t = np.hstack(((Q1_t-M_t)**2, (Q2_t-M_t)**2, (Q3_t-M_t)**2, (Q4_t-M_t)**2, var_t))\n",
    "    E_t = E_t.T\n",
    "\n",
    "\n",
    "    # solve optimization problem\n",
    "\n",
    "    optimal_weight, V100_adj, V100_t= solve_opt(X_opt,Y_opt, M_opt, M_adj, M_t, X_adj, X_t, \"aug\", E_opt, E_adj, E_t)\n",
    "    # opt_sol, V100_adj, V100_t = solve_opt(X_opt,Y_opt, M_opt, M_adj, M_t, X_adj, X_t, \"rkhs_poly\", degree = 2)\n",
    "    # opt_sol, V100_adj, V100_t = solve_opt(X_opt,Y_opt, M_opt, M_adj, M_t, X_adj, X_t, \"rkhs_rbf\", sigma = 1)\n",
    "\n",
    "    # adjust interval\n",
    "    if shrink: \n",
    "        alpha = 0.05\n",
    "        delta = interval_adj(X_adj,Y_adj,M_adj,V100_adj,alpha,stepsize = 0.001)\n",
    "\n",
    "        # plot\n",
    "        V_alpha_t = delta*V100_t\n",
    "    else:\n",
    "        V_alpha_t = V100_t\n",
    "    \n",
    "    coverage = (np.power(Y_t[:,0]-M_t[:,0], 2) <= V_alpha_t[:,0]).mean()\n",
    "    bandwidth = np.mean(V_alpha_t[:,0])\n",
    "    print(\"The overall coverage for UTOPIA is\", coverage)\n",
    "    print(\"Mean bandwidth on test data for UTOPIA is\", bandwidth)\n",
    "    return X_t,Y_t,M_t,V_alpha_t,coverage,bandwidth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1501e604",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LQR_FRED_MD_MULTIVARIATE(data, seed):\n",
    "    np.random.seed(seed)\n",
    "    lin_idx = int(Data.shape[0] * 0.4)\n",
    "    quantile_idx = int(Data.shape[0] * 0.8)\n",
    "    lin_data, quantile_data, test_data = np.split(Data, [lin_idx, quantile_idx])\n",
    "\n",
    "    X_lin = lin_data[:,:-1]\n",
    "    Y_lin = lin_data[:,-1].reshape(-1,1)\n",
    "    y_lin = Y_lin[:,0]\n",
    "    X_quantile = quantile_data[:,:-1]\n",
    "    Y_quantile = quantile_data[:,-1].reshape(-1,1)\n",
    "    X_test = test_data[:,:-1]\n",
    "    Y_test = test_data[:,-1].reshape(-1,1)\n",
    "\n",
    "    # Estimate the mean using NN1\n",
    "    est_type = \"NN1\"\n",
    "    M_quantile, M_test = mean_est_others(est_type,X_lin,Y_lin,X_quantile,X_test)\n",
    "\n",
    "    # Estimate the quantile\n",
    "    alpha = 0.05\n",
    "\n",
    "    model_quantile = QuantileRegressor(quantile=1-(alpha/2), alpha=0)\n",
    "    model_quantile.fit(X_quantile, Y_quantile-M_quantile)\n",
    "    Q_test = model_quantile.predict(X_test)\n",
    "\n",
    "\n",
    "    V_test = Q_test**2\n",
    "    V_test = V_test.reshape(-1,1)\n",
    "    coverage = (np.power(Y_test[:,0]-M_test[:,0], 2) <= V_test[:,0]).mean()\n",
    "    bandwidth = np.mean(V_test[:,0])\n",
    "    print(\"The overall coverage for LQR is\", coverage)\n",
    "    print(\"Mean bandwidth on test data for LQR is\", bandwidth)\n",
    "    return X_test,Y_test,M_test,V_test, coverage, bandwidth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b1d9848",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SplitCF_FRED_MD_MULTIVARIATE(data, seed): \n",
    "    np.random.seed(seed)\n",
    "    lin_idx = int(Data.shape[0] * 0.4)\n",
    "    res_idx = int(Data.shape[0] * 0.8)\n",
    "    lin_data, res_data, test_data = np.split(Data, [lin_idx, res_idx])\n",
    "\n",
    "\n",
    "    X_lin = lin_data[:,:-1]\n",
    "    Y_lin = lin_data[:,1].reshape(-1,1)\n",
    "    y_lin = Y_lin[:,0]\n",
    "    X_res = res_data[:,:-1]\n",
    "    Y_res = res_data[:,1].reshape(-1,1)\n",
    "    y_res = Y_res[:,0]\n",
    "    X_test = test_data[:,:-1]\n",
    "    Y_test = test_data[:,1].reshape(-1,1)\n",
    "    y_test = Y_test[:,0]\n",
    "\n",
    "    # Estimate the mean using NN1\n",
    "    est_type = \"NN1\"\n",
    "    Y_res_pred, M_test = mean_est_others(est_type,X_lin,Y_lin,X_res,X_test)\n",
    "    y_res_pred = Y_res_pred[:,0]\n",
    "\n",
    "    # Calculate the conformity scores\n",
    "    residuals = np.abs(y_res - y_res_pred)\n",
    "\n",
    "    alpha = 0.05  # 95% confidence level\n",
    "    k = int((1 - alpha) * len(y_lin))\n",
    "    residuals_sorted = np.sort(residuals)\n",
    "    threshold = residuals_sorted[k]\n",
    "\n",
    "    # Calculate the prediction interval\n",
    "    v_test = (threshold**2)*np.ones(len(y_test))\n",
    "    V_test = v_test.reshape(-1,1)\n",
    "    coverage = (np.power(Y_test[:,0]-M_test[:,0], 2) <= V_test[:,0]).mean()\n",
    "    bandwidth = np.mean(V_test[:,0])\n",
    "    print(\"The overall coverage for SplitCF is\", coverage)\n",
    "    print(\"Mean bandwidth on test data for SplitCF is\", bandwidth)\n",
    "    return X_test,Y_test,M_test,V_test,coverage,bandwidth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "81764873",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 453 and the array at index 1 has size 454",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m Data, Y_axis \u001b[38;5;241m=\u001b[39m \u001b[43mFRED_MD_DATA_PREP\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mUNRATE\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m seed_no \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m      4\u001b[0m X_t,Y_t,M_t,V_alpha_t,covarage,bandwidth \u001b[38;5;241m=\u001b[39m UTOPIA_FRED_MD_MULTIVARIATE(Data, seed \u001b[38;5;241m=\u001b[39m seed_no, shrink \u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[24], line 23\u001b[0m, in \u001b[0;36mFRED_MD_DATA_PREP\u001b[0;34m(index_type)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndex type must be one of UNRATE, HOUST or FEDFUNDS!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Remove outliers (w.r.t Y ) using IQR\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m Data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43mY\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m Q1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mpercentile(Y, \u001b[38;5;241m25\u001b[39m, interpolation \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmidpoint\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     26\u001b[0m Q3 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mpercentile(Y, \u001b[38;5;241m75\u001b[39m, interpolation \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmidpoint\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mhstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/numpy/core/shape_base.py:345\u001b[0m, in \u001b[0;36mhstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _nx\u001b[38;5;241m.\u001b[39mconcatenate(arrs, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    344\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 453 and the array at index 1 has size 454"
     ]
    }
   ],
   "source": [
    "Data, Y_axis = FRED_MD_DATA_PREP('UNRATE')\n",
    "seed_no = 100\n",
    "\n",
    "X_t,Y_t,M_t,V_alpha_t,covarage,bandwidth = UTOPIA_FRED_MD_MULTIVARIATE(Data, seed = seed_no, shrink =True)\n",
    "X_test,Y_test,M_test,V_test,covarage,bandwidth = LQR_FRED_MD_MULTIVARIATE(Data, seed = seed_no)\n",
    "X_test,Y_test,M_test,V_test,coverage,bandwidth = SplitCF_FRED_MD_MULTIVARIATE(Data, seed = seed_no)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed7ed7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/42/lzyqp82x5n97th0ryxnzvq440000gn/T/ipykernel_87705/2195563893.py:23: DeprecationWarning: the `interpolation=` argument to percentile was renamed to `method=`, which has additional options.\n",
      "Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n",
      "  Q1 = np.percentile(Y, 25, interpolation = 'midpoint')\n",
      "/var/folders/42/lzyqp82x5n97th0ryxnzvq440000gn/T/ipykernel_87705/2195563893.py:25: DeprecationWarning: the `interpolation=` argument to percentile was renamed to `method=`, which has additional options.\n",
      "Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n",
      "  Q3 = np.percentile(Y, 75, interpolation = 'midpoint')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of data being removed is  12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dm8341/anaconda3/lib/python3.10/site-packages/quantile_forest/_quantile_forest.py:104: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  super(BaseForestQuantileRegressor, self).fit(X, y, sample_weight=sample_weight)\n",
      "/Users/dm8341/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dm8341/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The overall coverage for UTOPIA is 0.8926174496644296\n",
      "Mean bandwidth on test data for UTOPIA is 0.540608007979174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dm8341/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dm8341/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_quantile.py:186: FutureWarning: The default solver will change from 'interior-point' to 'highs' in version 1.4. Set `solver='highs'` or to the desired solver to silence this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The overall coverage for LQR is 0.9328859060402684\n",
      "Mean bandwidth on test data for LQR is 1.0366449149411578\n",
      "The overall coverage for SplitCF is 0.9530201342281879\n",
      "Mean bandwidth on test data for SplitCF is 0.40053667278668226\n"
     ]
    }
   ],
   "source": [
    "Data, Y_axis = FRED_MD_DATA_PREP('HOUST')\n",
    "seed_no = 100\n",
    "\n",
    "X_t,Y_t,M_t,V_alpha_t,covarage,bandwidth = UTOPIA_FRED_MD_MULTIVARIATE(Data, seed = seed_no, shrink = False)\n",
    "X_test,Y_test,M_test,V_test,covarage,bandwidth = LQR_FRED_MD_MULTIVARIATE(Data, seed = seed_no)\n",
    "X_test,Y_test,M_test,V_test,coverage,bandwidth = SplitCF_FRED_MD_MULTIVARIATE(Data, seed = seed_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9d41827",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/42/lzyqp82x5n97th0ryxnzvq440000gn/T/ipykernel_87705/2195563893.py:23: DeprecationWarning: the `interpolation=` argument to percentile was renamed to `method=`, which has additional options.\n",
      "Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n",
      "  Q1 = np.percentile(Y, 25, interpolation = 'midpoint')\n",
      "/var/folders/42/lzyqp82x5n97th0ryxnzvq440000gn/T/ipykernel_87705/2195563893.py:25: DeprecationWarning: the `interpolation=` argument to percentile was renamed to `method=`, which has additional options.\n",
      "Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n",
      "  Q3 = np.percentile(Y, 75, interpolation = 'midpoint')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of data being removed is  23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dm8341/anaconda3/lib/python3.10/site-packages/quantile_forest/_quantile_forest.py:104: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  super(BaseForestQuantileRegressor, self).fit(X, y, sample_weight=sample_weight)\n",
      "/Users/dm8341/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dm8341/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The overall coverage for UTOPIA is 0.815068493150685\n",
      "Mean bandwidth on test data for UTOPIA is 0.04523479792113886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dm8341/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dm8341/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_quantile.py:186: FutureWarning: The default solver will change from 'interior-point' to 'highs' in version 1.4. Set `solver='highs'` or to the desired solver to silence this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The overall coverage for LQR is 0.9452054794520548\n",
      "Mean bandwidth on test data for LQR is 0.12248205205555908\n",
      "The overall coverage for SplitCF is 0.9657534246575342\n",
      "Mean bandwidth on test data for SplitCF is 0.45848004892735644\n"
     ]
    }
   ],
   "source": [
    "Data, Y_axis = FRED_MD_DATA_PREP('FEDFUNDS')\n",
    "seed_no = 100\n",
    "\n",
    "X_t,Y_t,M_t,V_alpha_t,covarage,bandwidth = UTOPIA_FRED_MD_MULTIVARIATE(Data, seed = seed_no)\n",
    "X_test,Y_test,M_test,V_test,covarage,bandwidth = LQR_FRED_MD_MULTIVARIATE(Data, seed = seed_no)\n",
    "X_test,Y_test,M_test,V_test,coverage,bandwidth = SplitCF_FRED_MD_MULTIVARIATE(Data, seed = seed_no)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
