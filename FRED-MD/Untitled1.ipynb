{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3314394a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from all_functions import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eeece343",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FRED_MD_DATA_PREP(index_type): \n",
    "    X = pd.read_csv('X_pca_top3.CSV')\n",
    "    X = X.to_numpy()[:,1:]\n",
    "    Y = pd.read_csv('Scaled_values_of_Y.CSV')\n",
    "    Y = Y.to_numpy()[:,1:]\n",
    "\n",
    "\n",
    "    # We use X to predict Y = \"UNRATE\"\n",
    "    if index_type == 'UNRATE':\n",
    "        Y_axis = \"UNRATE\"\n",
    "        Y = Y[:,0].reshape(-1,1)\n",
    "    elif index_type == 'HOUST':\n",
    "        Y_axis = \"HOUST\"\n",
    "        Y = Y[:,1].reshape(-1,1)\n",
    "    elif index_type == 'FEDFUNDS':\n",
    "        Y_axis = \"FEDFUNDS\"\n",
    "        Y = Y[:,2].reshape(-1,1)\n",
    "    else: \n",
    "        raise Exception(\"Index type must be one of UNRATE, HOUST or FEDFUNDS!\")\n",
    "\n",
    "    # Remove outliers (w.r.t Y ) using IQR\n",
    "    Data = np.hstack([X,Y])\n",
    "    Q1 = np.percentile(Y, 25, interpolation = 'midpoint')\n",
    "\n",
    "    Q3 = np.percentile(Y, 75, interpolation = 'midpoint')\n",
    "    IQR = Q3 - Q1\n",
    "    upper=Q3+1.5*IQR\n",
    "    upper_array=np.array(Y<=upper)\n",
    "    lower=Q1-1.5*IQR\n",
    "    lower_array=np.array(Y>=lower)\n",
    "    index_keep = upper_array & lower_array\n",
    "    Data = Data[index_keep[:,0].tolist(),:]\n",
    "    print(\"The number of data being removed is \", Y.shape[0]-Data.shape[0])\n",
    "    return Data, Y_axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b502f44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def UTOPIA_FRED_MD_MULTIVARIATE(data, seed = 0):\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(Data)\n",
    "    train_idx = int(Data.shape[0] * 0.8)\n",
    "    train_data, test_data = np.split(Data, [train_idx])\n",
    "    X_pre = train_data[:,:-1]\n",
    "    Y_pre = train_data[:,-1].reshape(-1,1)\n",
    "    X_opt = train_data[:,:-1]\n",
    "    Y_opt = train_data[:,-1].reshape(-1,1)\n",
    "    X_adj = train_data[:,:-1]\n",
    "    Y_adj = train_data[:,-1].reshape(-1,1)\n",
    "    X_t = test_data[:,:-1]\n",
    "    Y_t = test_data[:,-1].reshape(-1,1)\n",
    "\n",
    "\n",
    "    n_pre = len(Y_pre)\n",
    "    n_opt = len(Y_opt)\n",
    "    n_adj = len(Y_adj)\n",
    "    n_t = len(Y_t)\n",
    "\n",
    "    # Obtain mean estimator\n",
    "    known_mean = \"False\"\n",
    "    if known_mean == \"True\":\n",
    "        M_pre = np.zeros(n_pre).reshape(-1,1)\n",
    "        M_opt = np.zeros(n_opt).reshape(-1,1)\n",
    "        M_adj = np.zeros(n_adj).reshape(-1,1)\n",
    "        M_t = np.zeros(n_t).reshape(-1,1)\n",
    "    else:\n",
    "        est_type = \"NN1\"\n",
    "        M_pre, M_opt, M_adj, M_t = mean_est(est_type,X_pre,Y_pre,X_opt,X_adj,X_t)\n",
    "\n",
    "    # Obtain variance estimator\n",
    "    var_opt, var_adj, var_t = var_est(X_pre,Y_pre,M_pre, X_opt,X_adj,X_t,est_type =\"NN1\")\n",
    "\n",
    "\n",
    "    # Obtain quantile estimators\n",
    "    quantile = [0.05,0.35,0.65,0.95]\n",
    "    m1,Q1_opt,Q1_adj,Q1_t = est_quantile(\"NN1\",quantile[0],X_pre,Y_pre,X_opt,X_adj,X_t)\n",
    "    m2,Q2_opt,Q2_adj,Q2_t = est_quantile(\"NN2\",quantile[1],X_pre,Y_pre,X_opt,X_adj,X_t)\n",
    "    m3,Q3_opt,Q3_adj,Q3_t = est_quantile(\"qrf\",quantile[2],X_pre,Y_pre,X_opt,X_adj,X_t)\n",
    "    m4,Q4_opt,Q4_adj,Q4_t = est_quantile(\"gb\",quantile[3],X_pre,Y_pre,X_opt,X_adj,X_t)\n",
    "\n",
    "    # construct estimator matrix\n",
    "    E_opt = np.hstack(((Q1_opt-M_opt)**2, (Q2_opt-M_opt)**2, (Q3_opt-M_opt)**2, (Q4_opt-M_opt)**2, var_opt))\n",
    "    E_opt = E_opt.T\n",
    "    E_adj = np.hstack(((Q1_adj-M_adj)**2, (Q2_adj-M_adj)**2, (Q3_adj-M_adj)**2, (Q4_adj-M_adj)**2, var_adj))\n",
    "    E_adj = E_adj.T\n",
    "    E_t = np.hstack(((Q1_t-M_t)**2, (Q2_t-M_t)**2, (Q3_t-M_t)**2, (Q4_t-M_t)**2, var_t))\n",
    "    E_t = E_t.T\n",
    "\n",
    "\n",
    "    # solve optimization problem\n",
    "\n",
    "    optimal_weight, V100_adj, V100_t= solve_opt(X_opt,Y_opt, M_opt, M_adj, M_t, X_adj, X_t, \"aug\", E_opt, E_adj, E_t)\n",
    "    # opt_sol, V100_adj, V100_t = solve_opt(X_opt,Y_opt, M_opt, M_adj, M_t, X_adj, X_t, \"rkhs_poly\", degree = 2)\n",
    "    # opt_sol, V100_adj, V100_t = solve_opt(X_opt,Y_opt, M_opt, M_adj, M_t, X_adj, X_t, \"rkhs_rbf\", sigma = 1)\n",
    "\n",
    "    # adjust interval\n",
    "    alpha = 0.05\n",
    "    delta = interval_adj(X_adj,Y_adj,M_adj,V100_adj,alpha,stepsize = 0.001)\n",
    "\n",
    "    # plot\n",
    "    V_alpha_t = delta*V100_t\n",
    "    coverage = (np.power(Y_t[:,0]-M_t[:,0], 2) <= V_alpha_t[:,0]).mean()\n",
    "    bandwidth = np.mean(V_alpha_t[:,0])\n",
    "    print(\"The overall coverage for UTOPIA is\", coverage)\n",
    "    print(\"Mean bandwidth on test data for UTOPIA is\", bandwidth)\n",
    "    return X_t,Y_t,M_t,V_alpha_t,coverage,bandwidth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c46b6d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LQR_FRED_MD(data, seed):\n",
    "    np.random.seed(seed)\n",
    "    lin_idx = int(Data.shape[0] * 0.4)\n",
    "    quantile_idx = int(Data.shape[0] * 0.8)\n",
    "    lin_data, quantile_data, test_data = np.split(Data, [lin_idx, quantile_idx])\n",
    "\n",
    "    X_lin = lin_data[:,:-1]\n",
    "    Y_lin = lin_data[:,-1].reshape(-1,1)\n",
    "    y_lin = Y_lin[:,0]\n",
    "    X_quantile = quantile_data[:,:-1].reshape(-1,1)\n",
    "    Y_quantile = quantile_data[:,-1].reshape(-1,1)\n",
    "    X_test = test_data[:,:-1].reshape(-1,1)\n",
    "    Y_test = test_data[:,-1].reshape(-1,1)\n",
    "\n",
    "    # Estimate the mean using NN1\n",
    "    est_type = \"NN1\"\n",
    "    M_quantile, M_test = mean_est_others(est_type,X_lin,Y_lin,X_quantile,X_test)\n",
    "\n",
    "    # Estimate the quantile\n",
    "    alpha = 0.05\n",
    "\n",
    "    model_quantile = QuantileRegressor(quantile=1-(alpha/2), alpha=0)\n",
    "    model_quantile.fit(X_quantile, Y_quantile-M_quantile)\n",
    "    Q_test = model_quantile.predict(X_test)\n",
    "\n",
    "\n",
    "    V_test = Q_test**2\n",
    "    V_test = V_test.reshape(-1,1)\n",
    "    coverage = (np.power(Y_test[:,0]-M_test[:,0], 2) <= V_test[:,0]).mean()\n",
    "    bandwidth = np.mean(V_test[:,0])\n",
    "    print(\"The overall coverage for LQR is\", coverage)\n",
    "    print(\"Mean bandwidth on test data for LQR is\", bandwidth)\n",
    "    return X_test,Y_test,M_test,V_test, coverage, bandwidth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cc1b6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/42/lzyqp82x5n97th0ryxnzvq440000gn/T/ipykernel_77037/2195563893.py:23: DeprecationWarning: the `interpolation=` argument to percentile was renamed to `method=`, which has additional options.\n",
      "Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n",
      "  Q1 = np.percentile(Y, 25, interpolation = 'midpoint')\n",
      "/var/folders/42/lzyqp82x5n97th0ryxnzvq440000gn/T/ipykernel_77037/2195563893.py:25: DeprecationWarning: the `interpolation=` argument to percentile was renamed to `method=`, which has additional options.\n",
      "Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n",
      "  Q3 = np.percentile(Y, 75, interpolation = 'midpoint')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of data being removed is  8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dm8341/anaconda3/lib/python3.10/site-packages/quantile_forest/_quantile_forest.py:104: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  super(BaseForestQuantileRegressor, self).fit(X, y, sample_weight=sample_weight)\n",
      "/Users/dm8341/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dm8341/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The overall coverage for UTOPIA is 0.8053691275167785\n",
      "Mean bandwidth on test data for UTOPIA is 0.265970410396912\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (894x1 and 3x10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m seed_no \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      4\u001b[0m X_t,Y_t,M_t,V_alpha_t,covarage,bandwidth \u001b[38;5;241m=\u001b[39m UTOPIA_FRED_MD_MULTIVARIATE(Data, seed \u001b[38;5;241m=\u001b[39m seed_no)\n\u001b[0;32m----> 5\u001b[0m X_test,Y_test,M_test,V_test,covarage,bandwidth \u001b[38;5;241m=\u001b[39m \u001b[43mLQR_FRED_MD\u001b[49m\u001b[43m(\u001b[49m\u001b[43mData\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mseed_no\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 17\u001b[0m, in \u001b[0;36mLQR_FRED_MD\u001b[0;34m(data, seed)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Estimate the mean using NN1\u001b[39;00m\n\u001b[1;32m     16\u001b[0m est_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNN1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 17\u001b[0m M_quantile, M_test \u001b[38;5;241m=\u001b[39m \u001b[43mmean_est_others\u001b[49m\u001b[43m(\u001b[49m\u001b[43mest_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43mX_lin\u001b[49m\u001b[43m,\u001b[49m\u001b[43mY_lin\u001b[49m\u001b[43m,\u001b[49m\u001b[43mX_quantile\u001b[49m\u001b[43m,\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Estimate the quantile\u001b[39;00m\n\u001b[1;32m     20\u001b[0m alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.05\u001b[39m\n",
      "File \u001b[0;32m~/Documents/GitHub/PI/FRED-MD/all_functions.py:668\u001b[0m, in \u001b[0;36mmean_est_others\u001b[0;34m(est_type, X_lin, Y_lin, X_quantile, X_test)\u001b[0m\n\u001b[1;32m    666\u001b[0m     \u001b[38;5;66;03m#updating parameters\u001b[39;00m\n\u001b[1;32m    667\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m--> 668\u001b[0m M_quantile \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_quantile\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    669\u001b[0m M_quantile \u001b[38;5;241m=\u001b[39m M_quantile\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    670\u001b[0m M_test \u001b[38;5;241m=\u001b[39m model(torch\u001b[38;5;241m.\u001b[39mfrom_numpy(X_test)\u001b[38;5;241m.\u001b[39mfloat())\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/GitHub/PI/FRED-MD/all_functions.py:38\u001b[0m, in \u001b[0;36mNN1.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 38\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     39\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x)\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (894x1 and 3x10)"
     ]
    }
   ],
   "source": [
    "Data, Y_axis = FRED_MD_DATA_PREP('UNRATE')\n",
    "seed_no = 0\n",
    "\n",
    "X_t,Y_t,M_t,V_alpha_t,covarage,bandwidth = UTOPIA_FRED_MD_MULTIVARIATE(Data, seed = seed_no)\n",
    "X_test,Y_test,M_test,V_test,covarage,bandwidth = LQR_FRED_MD(Data, seed = seed_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0ad7cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "lin_idx = int(Data.shape[0] * 0.4)\n",
    "quantile_idx = int(Data.shape[0] * 0.8)\n",
    "lin_data, quantile_data, test_data = np.split(Data, [lin_idx, quantile_idx])\n",
    "\n",
    "X_lin = lin_data[:,:-1]\n",
    "Y_lin = lin_data[:,-1].reshape(-1,1)\n",
    "y_lin = Y_lin[:,0]\n",
    "X_quantile = quantile_data[:,:-1].reshape(-1,1)\n",
    "Y_quantile = quantile_data[:,-1].reshape(-1,1)\n",
    "X_test = test_data[:,:-1].reshape(-1,1)\n",
    "Y_test = test_data[:,-1].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "429d6e4d",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (894x1 and 3x10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m est_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNN1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m M_quantile, M_test \u001b[38;5;241m=\u001b[39m \u001b[43mmean_est_others\u001b[49m\u001b[43m(\u001b[49m\u001b[43mest_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43mX_lin\u001b[49m\u001b[43m,\u001b[49m\u001b[43mY_lin\u001b[49m\u001b[43m,\u001b[49m\u001b[43mX_quantile\u001b[49m\u001b[43m,\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/PI/FRED-MD/all_functions.py:668\u001b[0m, in \u001b[0;36mmean_est_others\u001b[0;34m(est_type, X_lin, Y_lin, X_quantile, X_test)\u001b[0m\n\u001b[1;32m    666\u001b[0m     \u001b[38;5;66;03m#updating parameters\u001b[39;00m\n\u001b[1;32m    667\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m--> 668\u001b[0m M_quantile \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_quantile\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    669\u001b[0m M_quantile \u001b[38;5;241m=\u001b[39m M_quantile\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    670\u001b[0m M_test \u001b[38;5;241m=\u001b[39m model(torch\u001b[38;5;241m.\u001b[39mfrom_numpy(X_test)\u001b[38;5;241m.\u001b[39mfloat())\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/GitHub/PI/FRED-MD/all_functions.py:38\u001b[0m, in \u001b[0;36mNN1.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 38\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     39\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x)\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (894x1 and 3x10)"
     ]
    }
   ],
   "source": [
    "est_type = \"NN1\"\n",
    "M_quantile, M_test = mean_est_others(est_type,X_lin,Y_lin,X_quantile,X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
