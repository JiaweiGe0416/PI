{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c6ece98",
   "metadata": {},
   "source": [
    "Linear quantile regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "778270c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.lines as lines\n",
    "from sklearn.linear_model import QuantileRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn # All neural network modules, nn.Linear, nn.Conv2d, BatchNorm, Loss functions\n",
    "import torch.optim as optim # For all Optimization algorithms, SGD, Adam, etc.\n",
    "import torch.nn.functional as F # All functions that don't have any parameters\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from quantile_forest import RandomForestQuantileRegressor\n",
    "\n",
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "from numpy import linalg\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.linalg import sqrtm\n",
    "import math\n",
    "\n",
    "random_seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b82043ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-layer NN\n",
    "class NN1(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(NN1, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 10)\n",
    "        self.fc2 = nn.Linear(10, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "# 2-layer NN\n",
    "class NN2(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(NN2, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 50)\n",
    "        self.fc2 = nn.Linear(50, 50)\n",
    "        self.fc3 = nn.Linear(50, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c53156e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train mean estimator that estimate E[Y|X]\n",
    "def mean_est(est_type,X_lin,Y_lin,X_quantile,X_test):\n",
    "    if est_type == \"NN1\":\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        torch.manual_seed(42)\n",
    "        torch.cuda.manual_seed_all(42) \n",
    "        model = NN1(input_size=3, output_size=1).to(device)\n",
    "        criterion=nn.MSELoss()\n",
    "        learning_rate = 0.001\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        for epoch in range(1000):\n",
    "            #convert numpy array to torch Variable\n",
    "            inputs=Variable(torch.from_numpy(X_lin))\n",
    "            labels=Variable(torch.from_numpy(Y_lin))\n",
    "            \n",
    "            #clear gradients wrt parameters\n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "            #Forward to get outputs\n",
    "            outputs=model(inputs.float())\n",
    "    \n",
    "            #calculate loss\n",
    "            loss=criterion(outputs.float(), labels.float())\n",
    "    \n",
    "            #getting gradients wrt parameters\n",
    "            loss.backward()\n",
    "    \n",
    "            #updating parameters\n",
    "            optimizer.step()\n",
    "        M_quantile = model(torch.from_numpy(X_quantile).float())\n",
    "        M_quantile = M_quantile.detach().cpu().numpy().reshape(-1,1)\n",
    "        M_test = model(torch.from_numpy(X_test).float())\n",
    "        M_test = M_test.detach().cpu().numpy().reshape(-1,1)\n",
    "        return M_quantile, M_test\n",
    "    if est_type == \"NN2\":\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        torch.manual_seed(42)\n",
    "        torch.cuda.manual_seed_all(42) \n",
    "        model = NN2(input_size=3, output_size=1).to(device)\n",
    "        criterion=nn.MSELoss()\n",
    "        learning_rate = 0.001\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        for epoch in range(1000):\n",
    "            #convert numpy array to torch Variable\n",
    "            inputs=Variable(torch.from_numpy(X_lin))\n",
    "            labels=Variable(torch.from_numpy(Y_lin))\n",
    "    \n",
    "            #clear gradients wrt parameters\n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "            #Forward to get outputs\n",
    "            outputs=model(inputs.float())\n",
    "    \n",
    "            #calculate loss\n",
    "            loss=criterion(outputs.float(), labels.float())\n",
    "    \n",
    "            #getting gradients wrt parameters\n",
    "            loss.backward()\n",
    "    \n",
    "            #updating parameters\n",
    "            optimizer.step()\n",
    "        M_quantile = model(torch.from_numpy(X_quantile).float())\n",
    "        M_quantile = M_quantile.detach().cpu().numpy().reshape(-1,1)\n",
    "        M_test = model(torch.from_numpy(X_test).float())\n",
    "        M_test = M_test.detach().cpu().numpy().reshape(-1,1)\n",
    "        return M_quantile, M_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a3dad34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate points uniformly distributed on the surface of a sphere\n",
    "\n",
    "def generate_points_on_sphere(n):\n",
    "    phi = np.random.uniform(0, 2*np.pi, size=n)\n",
    "    cos_theta = np.random.uniform(-1, 1, size=n)\n",
    "    theta = np.arccos(cos_theta)\n",
    "\n",
    "    x = np.sin(theta) * np.cos(phi)\n",
    "    y = np.sin(theta) * np.sin(phi)\n",
    "    z = np.cos(theta)\n",
    "\n",
    "    return np.stack((x, y, z), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66438848",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiawei/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jiawei/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_quantile.py:186: FutureWarning: The default solver will change from 'interior-point' to 'highs' in version 1.4. Set `solver='highs'` or to the desired solver to silence this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The overall coverage is 0.969\n",
      "The mean bandwidth for testing data is 10.728016689819828\n"
     ]
    }
   ],
   "source": [
    "# Test 1\n",
    "\n",
    "# Generate i.i.d data\n",
    "np.random.seed(5)\n",
    "n_pre = 1000\n",
    "n_opt = 500\n",
    "n_adj = 100\n",
    "n_t = 1000\n",
    "n = n_pre+n_opt+n_adj+n_t\n",
    "beta = np.array([1/math.sqrt(3),1/math.sqrt(3),-1/math.sqrt(3)])\n",
    "\n",
    "X = generate_points_on_sphere(n)\n",
    "Y = np.sqrt(1+25*np.power(X @ beta, 4))  * np.random.uniform(-1, 1, n)\n",
    "Y = Y.reshape(-1,1)\n",
    "\n",
    "\n",
    "X_lin = X[0:600,:]\n",
    "Y_lin = Y[0:600,:]\n",
    "x_lin = X_lin[:,0]\n",
    "y_lin = Y_lin[:,0]\n",
    "n_lin = X_lin.shape[0]\n",
    "\n",
    "X_quantile = X[600:n_pre+n_opt+n_adj,:]\n",
    "Y_quantile = Y[600:n_pre+n_opt+n_adj,:]\n",
    "n_quantile = X_quantile.shape[0]\n",
    "\n",
    "X_test = X[n_pre+n_opt+n_adj:,:]\n",
    "Y_test = Y[n_pre+n_opt+n_adj:,:]\n",
    "n_test = X_test.shape[0]\n",
    "\n",
    "\n",
    "# Estimate the quantile\n",
    "M_quantile = np.zeros(n_quantile).reshape(-1,1)\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "model_quantile = QuantileRegressor(quantile=1-(alpha/2), alpha=0)\n",
    "model_quantile.fit(X_quantile, Y_quantile-M_quantile)\n",
    "Q_test = model_quantile.predict(X_test)\n",
    "\n",
    "\n",
    "M_test = np.zeros(n_test).reshape(-1,1)\n",
    "V_test = Q_test**2\n",
    "V_test = V_test.reshape(-1,1)\n",
    "\n",
    "coverage = (np.power(Y_test[:,0]-M_test[:,0], 2) <= V_test[:,0]).mean()\n",
    "bandwidth = np.mean(V_test[:,0])\n",
    "print(\"The overall coverage is\", coverage)\n",
    "print(\"The mean bandwidth for testing data is\", bandwidth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8056bf53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiawei/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jiawei/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_quantile.py:186: FutureWarning: The default solver will change from 'interior-point' to 'highs' in version 1.4. Set `solver='highs'` or to the desired solver to silence this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The overall coverage is 0.953\n",
      "The mean bandwidth for testing data is 10.056907548832976\n"
     ]
    }
   ],
   "source": [
    "# Test 2\n",
    "\n",
    "# Generate i.i.d data\n",
    "np.random.seed(0)\n",
    "n_pre = 1000\n",
    "n_opt = 1000\n",
    "n_adj = 100\n",
    "n_t = 1000\n",
    "n = n_pre+n_opt+n_adj+n_t\n",
    "beta = np.array([1/math.sqrt(3),1/math.sqrt(3),-1/math.sqrt(3)])\n",
    "\n",
    "X = generate_points_on_sphere(n)\n",
    "Y = 1+5*np.power(X @ beta, 3)+np.sqrt(1+25*np.power(X @ beta, 4))  * np.random.uniform(-1, 1, n)\n",
    "Y = Y.reshape(-1,1)\n",
    "\n",
    "X_lin = X[0:600,:]\n",
    "Y_lin = Y[0:600,:]\n",
    "x_lin = X_lin[:,0]\n",
    "y_lin = Y_lin[:,0]\n",
    "n_lin = X_lin.shape[0]\n",
    "\n",
    "X_quantile = X[600:n_pre+n_opt+n_adj,:]\n",
    "Y_quantile = Y[600:n_pre+n_opt+n_adj,:]\n",
    "n_quantile = X_quantile.shape[0]\n",
    "\n",
    "X_test = X[n_pre+n_opt+n_adj:,:]\n",
    "Y_test = Y[n_pre+n_opt+n_adj:,:]\n",
    "n_test = X_test.shape[0]\n",
    "\n",
    "\n",
    "# Estimate the mean using NN2\n",
    "est_type = \"NN2\"\n",
    "M_quantile, M_test = mean_est(est_type,X_lin,Y_lin,X_quantile,X_test)\n",
    "\n",
    "# Estimate the quantile\n",
    "alpha = 0.05\n",
    "\n",
    "model_quantile = QuantileRegressor(quantile=1-(alpha/2), alpha=0)\n",
    "model_quantile.fit(X_quantile, Y_quantile-M_quantile)\n",
    "Q_test = model_quantile.predict(X_test)\n",
    "\n",
    "\n",
    "V_test = Q_test**2\n",
    "V_test = V_test.reshape(-1,1)\n",
    "\n",
    "coverage = (np.power(Y_test[:,0]-M_test[:,0], 2) <= V_test[:,0]).mean()\n",
    "bandwidth = np.mean(V_test[:,0])\n",
    "print(\"The overall coverage is\", coverage)\n",
    "print(\"The mean bandwidth for testing data is\", bandwidth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbbf5a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiawei/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jiawei/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_quantile.py:186: FutureWarning: The default solver will change from 'interior-point' to 'highs' in version 1.4. Set `solver='highs'` or to the desired solver to silence this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The overall coverage is 0.943\n",
      "The mean bandwidth for testing data is 22.928315704490675\n"
     ]
    }
   ],
   "source": [
    "# Test 3\n",
    "\n",
    "# Generate i.i.d data (Y follows a constrained Laplace)\n",
    "np.random.seed(1)\n",
    "n_pre = 1000\n",
    "n_opt = 500\n",
    "n_adj = 100\n",
    "n_t = 1000\n",
    "n = n_pre+n_opt+n_adj+n_t\n",
    "beta = np.array([1/math.sqrt(3),1/math.sqrt(3),-1/math.sqrt(3)])\n",
    "\n",
    "X = generate_points_on_sphere(n)\n",
    "\n",
    "# Specify the mean and standard deviation for Y\n",
    "mean_Y = np.power(X @ beta, 2)+5*np.power(X @ beta, 4)\n",
    "std_dev_Y = np.sqrt(1 + 25 * np.power(X @ beta, 4))\n",
    "mean_Y = mean_Y.reshape(-1,1)\n",
    "std_dev_Y  = std_dev_Y .reshape(-1,1)\n",
    "\n",
    "# Specify the bounds for Y\n",
    "lower_bound = mean_Y - 2 * std_dev_Y\n",
    "upper_bound = mean_Y + 2 * std_dev_Y\n",
    "\n",
    "# Generate all Y values initially\n",
    "Y = np.random.laplace(mean_Y, std_dev_Y)\n",
    "\n",
    "# Correct values that fall out of bounds\n",
    "while True:\n",
    "    out_of_bounds = (Y < lower_bound) | (Y > upper_bound)\n",
    "    if not np.any(out_of_bounds):\n",
    "        break\n",
    "    Y[out_of_bounds] = np.random.laplace(mean_Y[out_of_bounds], std_dev_Y[out_of_bounds])\n",
    "    \n",
    "\n",
    "X_lin = X[0:600,:]\n",
    "Y_lin = Y[0:600,:]\n",
    "x_lin = X_lin[:,0]\n",
    "y_lin = Y_lin[:,0]\n",
    "n_lin = X_lin.shape[0]\n",
    "\n",
    "X_quantile = X[600:n_pre+n_opt+n_adj,:]\n",
    "Y_quantile = Y[600:n_pre+n_opt+n_adj,:]\n",
    "n_quantile = X_quantile.shape[0]\n",
    "\n",
    "X_test = X[n_pre+n_opt+n_adj:,:]\n",
    "Y_test = Y[n_pre+n_opt+n_adj:,:]\n",
    "n_test = X_test.shape[0]\n",
    "\n",
    "# Estimate the mean using NN2\n",
    "est_type = \"NN2\"\n",
    "M_quantile, M_test = mean_est(est_type,X_lin,Y_lin,X_quantile,X_test)\n",
    "\n",
    "\n",
    "# Estimate the quantile\n",
    "alpha = 0.05\n",
    "\n",
    "model_quantile = QuantileRegressor(quantile=1-(alpha/2), alpha=0)\n",
    "model_quantile.fit(X_quantile, Y_quantile-M_quantile)\n",
    "Q_test = model_quantile.predict(X_test)\n",
    "\n",
    "\n",
    "V_test = Q_test**2\n",
    "V_test = V_test.reshape(-1,1)\n",
    "\n",
    "coverage = (np.power(Y_test[:,0]-M_test[:,0], 2) <= V_test[:,0]).mean()\n",
    "bandwidth = np.mean(V_test[:,0])\n",
    "print(\"The overall coverage is\", coverage)\n",
    "print(\"The mean bandwidth for testing data is\", bandwidth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0a66280",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiawei/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jiawei/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_quantile.py:186: FutureWarning: The default solver will change from 'interior-point' to 'highs' in version 1.4. Set `solver='highs'` or to the desired solver to silence this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The overall coverage is 0.943\n",
      "The mean bandwidth for testing data is 56.161555004050896\n"
     ]
    }
   ],
   "source": [
    "# Test 4\n",
    "\n",
    "# Generate i.i.d data (Y follows a constrained Laplace)\n",
    "np.random.seed(1)\n",
    "n_pre = 1000\n",
    "n_opt = 500\n",
    "n_adj = 100\n",
    "n_t = 1000\n",
    "n = n_pre+n_opt+n_adj+n_t\n",
    "beta = np.array([1/math.sqrt(3),1/math.sqrt(3),-1/math.sqrt(3)])\n",
    "\n",
    "X = generate_points_on_sphere(n)\n",
    "\n",
    "# Specify the mean and standard deviation for Y\n",
    "mean_Y = np.power(X @ beta, 2)+5*np.power(X @ beta, 4)\n",
    "std_dev_Y = np.sqrt(1 + 25 * np.power(X @ beta, 4))\n",
    "mean_Y = mean_Y.reshape(-1,1)\n",
    "std_dev_Y  = std_dev_Y .reshape(-1,1)\n",
    "\n",
    "\n",
    "# Generate all Y values initially\n",
    "Y = np.random.laplace(mean_Y, std_dev_Y)\n",
    "\n",
    "    \n",
    "\n",
    "X_lin = X[0:600,:]\n",
    "Y_lin = Y[0:600,:]\n",
    "x_lin = X_lin[:,0]\n",
    "y_lin = Y_lin[:,0]\n",
    "n_lin = X_lin.shape[0]\n",
    "\n",
    "X_quantile = X[600:n_pre+n_opt+n_adj,:]\n",
    "Y_quantile = Y[600:n_pre+n_opt+n_adj,:]\n",
    "n_quantile = X_quantile.shape[0]\n",
    "\n",
    "X_test = X[n_pre+n_opt+n_adj:,:]\n",
    "Y_test = Y[n_pre+n_opt+n_adj:,:]\n",
    "n_test = X_test.shape[0]\n",
    "\n",
    "# Estimate the mean using NN2\n",
    "est_type = \"NN2\"\n",
    "M_quantile, M_test = mean_est(est_type,X_lin,Y_lin,X_quantile,X_test)\n",
    "\n",
    "\n",
    "# Estimate the quantile\n",
    "alpha = 0.05\n",
    "\n",
    "model_quantile = QuantileRegressor(quantile=1-(alpha/2), alpha=0)\n",
    "model_quantile.fit(X_quantile, Y_quantile-M_quantile)\n",
    "Q_test = model_quantile.predict(X_test)\n",
    "\n",
    "\n",
    "V_test = Q_test**2\n",
    "V_test = V_test.reshape(-1,1)\n",
    "\n",
    "coverage = (np.power(Y_test[:,0]-M_test[:,0], 2) <= V_test[:,0]).mean()\n",
    "bandwidth = np.mean(V_test[:,0])\n",
    "print(\"The overall coverage is\", coverage)\n",
    "print(\"The mean bandwidth for testing data is\", bandwidth)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
