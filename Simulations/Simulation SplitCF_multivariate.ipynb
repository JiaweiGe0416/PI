{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8041d15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.lines as lines\n",
    "from sklearn.linear_model import QuantileRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn # All neural network modules, nn.Linear, nn.Conv2d, BatchNorm, Loss functions\n",
    "import torch.optim as optim # For all Optimization algorithms, SGD, Adam, etc.\n",
    "import torch.nn.functional as F # All functions that don't have any parameters\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from quantile_forest import RandomForestQuantileRegressor\n",
    "\n",
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "from numpy import linalg\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.linalg import sqrtm\n",
    "import math\n",
    "\n",
    "random_seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffd27188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-layer NN\n",
    "class NN1(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(NN1, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 10)\n",
    "        self.fc2 = nn.Linear(10, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "# 2-layer NN\n",
    "class NN2(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(NN2, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 50)\n",
    "        self.fc2 = nn.Linear(50, 50)\n",
    "        self.fc3 = nn.Linear(50, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed84119c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train mean estimator that estimate E[Y|X]\n",
    "def mean_est(est_type,X_lin,Y_lin,X_quantile,X_test):\n",
    "    if est_type == \"NN1\":\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        torch.manual_seed(42)\n",
    "        torch.cuda.manual_seed_all(42) \n",
    "        model = NN1(input_size=3, output_size=1).to(device)\n",
    "        criterion=nn.MSELoss()\n",
    "        learning_rate = 0.001\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        for epoch in range(1000):\n",
    "            #convert numpy array to torch Variable\n",
    "            inputs=Variable(torch.from_numpy(X_lin))\n",
    "            labels=Variable(torch.from_numpy(Y_lin))\n",
    "            \n",
    "            #clear gradients wrt parameters\n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "            #Forward to get outputs\n",
    "            outputs=model(inputs.float())\n",
    "    \n",
    "            #calculate loss\n",
    "            loss=criterion(outputs.float(), labels.float())\n",
    "    \n",
    "            #getting gradients wrt parameters\n",
    "            loss.backward()\n",
    "    \n",
    "            #updating parameters\n",
    "            optimizer.step()\n",
    "        M_quantile = model(torch.from_numpy(X_quantile).float())\n",
    "        M_quantile = M_quantile.detach().cpu().numpy().reshape(-1,1)\n",
    "        M_test = model(torch.from_numpy(X_test).float())\n",
    "        M_test = M_test.detach().cpu().numpy().reshape(-1,1)\n",
    "        return M_quantile, M_test\n",
    "    if est_type == \"NN2\":\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        torch.manual_seed(42)\n",
    "        torch.cuda.manual_seed_all(42) \n",
    "        model = NN2(input_size=3, output_size=1).to(device)\n",
    "        criterion=nn.MSELoss()\n",
    "        learning_rate = 0.001\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        for epoch in range(1000):\n",
    "            #convert numpy array to torch Variable\n",
    "            inputs=Variable(torch.from_numpy(X_lin))\n",
    "            labels=Variable(torch.from_numpy(Y_lin))\n",
    "    \n",
    "            #clear gradients wrt parameters\n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "            #Forward to get outputs\n",
    "            outputs=model(inputs.float())\n",
    "    \n",
    "            #calculate loss\n",
    "            loss=criterion(outputs.float(), labels.float())\n",
    "    \n",
    "            #getting gradients wrt parameters\n",
    "            loss.backward()\n",
    "    \n",
    "            #updating parameters\n",
    "            optimizer.step()\n",
    "        M_quantile = model(torch.from_numpy(X_quantile).float())\n",
    "        M_quantile = M_quantile.detach().cpu().numpy().reshape(-1,1)\n",
    "        M_test = model(torch.from_numpy(X_test).float())\n",
    "        M_test = M_test.detach().cpu().numpy().reshape(-1,1)\n",
    "        return M_quantile, M_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb66c1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate points uniformly distributed on the surface of a sphere\n",
    "\n",
    "def generate_points_on_sphere(n):\n",
    "    phi = np.random.uniform(0, 2*np.pi, size=n)\n",
    "    cos_theta = np.random.uniform(-1, 1, size=n)\n",
    "    theta = np.arccos(cos_theta)\n",
    "\n",
    "    x = np.sin(theta) * np.cos(phi)\n",
    "    y = np.sin(theta) * np.sin(phi)\n",
    "    z = np.cos(theta)\n",
    "\n",
    "    return np.stack((x, y, z), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93504e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The overall coverage is 0.961\n",
      "The mean bandwidth for testing data is 9.553809433329123\n"
     ]
    }
   ],
   "source": [
    "# Test 1\n",
    "\n",
    "# Generate i.i.d data\n",
    "np.random.seed(5)\n",
    "n_pre = 1000\n",
    "n_opt = 500\n",
    "n_adj = 100\n",
    "n_t = 1000\n",
    "n = n_pre+n_opt+n_adj+n_t\n",
    "beta = np.array([1/math.sqrt(3),1/math.sqrt(3),-1/math.sqrt(3)])\n",
    "\n",
    "X = generate_points_on_sphere(n)\n",
    "Y = np.sqrt(1+25*np.power(X @ beta, 4))  * np.random.uniform(-1, 1, n)\n",
    "Y = Y.reshape(-1,1)\n",
    "\n",
    "X_lin = X[0:int((n_pre+n_opt+n_adj)/2),:]\n",
    "Y_lin = Y[0:int((n_pre+n_opt+n_adj)/2),:]\n",
    "x_lin = X_lin[:,0]\n",
    "y_lin = Y_lin[:,0]\n",
    "n_lin = X_lin.shape[0]\n",
    "\n",
    "X_res = X[int((n_pre+n_opt+n_adj)/2):n_pre+n_opt+n_adj,:]\n",
    "Y_res = Y[int((n_pre+n_opt+n_adj)/2):n_pre+n_opt+n_adj,:]\n",
    "x_res = X_res[:,0]\n",
    "y_res = Y_res[:,0]\n",
    "n_res = X_res.shape[0]\n",
    "\n",
    "X_test = X[n_pre+n_opt+n_adj:,:]\n",
    "Y_test = Y[n_pre+n_opt+n_adj:,:]\n",
    "x_test = X_test[:,0]\n",
    "y_test = Y_test[:,0]\n",
    "n_test = X_test.shape[0]\n",
    "\n",
    "\n",
    "# Calculate the conformity scores\n",
    "y_res_pred = np.zeros(n_res)\n",
    "residuals = np.abs(y_res - y_res_pred)\n",
    "\n",
    "alpha = 0.05  # 95% confidence level\n",
    "k = int((1 - alpha) * len(y_lin))\n",
    "residuals_sorted = np.sort(residuals)\n",
    "threshold = residuals_sorted[k]\n",
    "\n",
    "# Calculate the prediction interval\n",
    "m_test = np.zeros(n_test)\n",
    "M_test = m_test.reshape(-1,1)\n",
    "v_test = (threshold**2)*np.ones(len(m_test))\n",
    "V_test = v_test.reshape(-1,1)\n",
    "\n",
    "\n",
    "coverage = (np.power(Y_test[:,0]-M_test[:,0], 2) <= V_test[:,0]).mean()\n",
    "bandwidth = np.mean(V_test[:,0])\n",
    "print(\"The overall coverage is\", coverage)\n",
    "print(\"The mean bandwidth for testing data is\", bandwidth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ca97a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The overall coverage is 0.95\n",
      "The mean bandwidth for testing data is 10.001839736569222\n"
     ]
    }
   ],
   "source": [
    "# Test 2\n",
    "\n",
    "# Generate i.i.d data\n",
    "np.random.seed(0)\n",
    "n_pre = 1000\n",
    "n_opt = 1000\n",
    "n_adj = 100\n",
    "n_t = 1000\n",
    "n = n_pre+n_opt+n_adj+n_t\n",
    "beta = np.array([1/math.sqrt(3),1/math.sqrt(3),-1/math.sqrt(3)])\n",
    "\n",
    "X = generate_points_on_sphere(n)\n",
    "Y = 1+5*np.power(X @ beta, 3)+np.sqrt(1+25*np.power(X @ beta, 4))  * np.random.uniform(-1, 1, n)\n",
    "Y = Y.reshape(-1,1)\n",
    "\n",
    "X_lin = X[0:int((n_pre+n_opt+n_adj)/2),:]\n",
    "Y_lin = Y[0:int((n_pre+n_opt+n_adj)/2),:]\n",
    "x_lin = X_lin[:,0]\n",
    "y_lin = Y_lin[:,0]\n",
    "n_lin = X_lin.shape[0]\n",
    "\n",
    "X_res = X[int((n_pre+n_opt+n_adj)/2):n_pre+n_opt+n_adj,:]\n",
    "Y_res = Y[int((n_pre+n_opt+n_adj)/2):n_pre+n_opt+n_adj,:]\n",
    "x_res = X_res[:,0]\n",
    "y_res = Y_res[:,0]\n",
    "n_res = X_res.shape[0]\n",
    "\n",
    "X_test = X[n_pre+n_opt+n_adj:,:]\n",
    "Y_test = Y[n_pre+n_opt+n_adj:,:]\n",
    "x_test = X_test[:,0]\n",
    "y_test = Y_test[:,0]\n",
    "n_test = X_test.shape[0]\n",
    "\n",
    "\n",
    "# Estimate the mean using NN2\n",
    "est_type = \"NN2\"\n",
    "Y_res_pred, M_test = mean_est(est_type,X_lin,Y_lin,X_res,X_test)\n",
    "\n",
    "\n",
    "# Calculate the conformity scores\n",
    "y_res_pred = Y_res_pred[:,0]\n",
    "residuals = np.abs(y_res - y_res_pred)\n",
    "\n",
    "alpha = 0.05  # 95% confidence level\n",
    "k = int((1 - alpha) * len(y_lin))\n",
    "residuals_sorted = np.sort(residuals)\n",
    "threshold = residuals_sorted[k]\n",
    "\n",
    "# Calculate the prediction interval\n",
    "v_test = (threshold**2)*np.ones(len(y_test))\n",
    "V_test = v_test.reshape(-1,1)\n",
    "\n",
    "\n",
    "coverage = (np.power(Y_test[:,0]-M_test[:,0], 2) <= V_test[:,0]).mean()\n",
    "bandwidth = np.mean(V_test[:,0])\n",
    "print(\"The overall coverage is\", coverage)\n",
    "print(\"The mean bandwidth for testing data is\", bandwidth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de6a43e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The overall coverage is 0.955\n",
      "The mean bandwidth for testing data is 24.927261550311588\n"
     ]
    }
   ],
   "source": [
    "# Test 3\n",
    "\n",
    "# Generate i.i.d data (Y follows a constrained Laplace)\n",
    "np.random.seed(1)\n",
    "n_pre = 1000\n",
    "n_opt = 500\n",
    "n_adj = 100\n",
    "n_t = 1000\n",
    "n = n_pre+n_opt+n_adj+n_t\n",
    "beta = np.array([1/math.sqrt(3),1/math.sqrt(3),-1/math.sqrt(3)])\n",
    "\n",
    "X = generate_points_on_sphere(n)\n",
    "\n",
    "# Specify the mean and standard deviation for Y\n",
    "mean_Y = np.power(X @ beta, 2)+5*np.power(X @ beta, 4)\n",
    "std_dev_Y = np.sqrt(1 + 25 * np.power(X @ beta, 4))\n",
    "mean_Y = mean_Y.reshape(-1,1)\n",
    "std_dev_Y  = std_dev_Y .reshape(-1,1)\n",
    "\n",
    "# Specify the bounds for Y\n",
    "lower_bound = mean_Y - 2 * std_dev_Y\n",
    "upper_bound = mean_Y + 2 * std_dev_Y\n",
    "\n",
    "# Generate all Y values initially\n",
    "Y = np.random.laplace(mean_Y, std_dev_Y)\n",
    "\n",
    "# Correct values that fall out of bounds\n",
    "while True:\n",
    "    out_of_bounds = (Y < lower_bound) | (Y > upper_bound)\n",
    "    if not np.any(out_of_bounds):\n",
    "        break\n",
    "    Y[out_of_bounds] = np.random.laplace(mean_Y[out_of_bounds], std_dev_Y[out_of_bounds])\n",
    "\n",
    "    \n",
    "X_lin = X[0:int((n_pre+n_opt+n_adj)/2),:]\n",
    "Y_lin = Y[0:int((n_pre+n_opt+n_adj)/2),:]\n",
    "x_lin = X_lin[:,0]\n",
    "y_lin = Y_lin[:,0]\n",
    "n_lin = X_lin.shape[0]\n",
    "\n",
    "X_res = X[int((n_pre+n_opt+n_adj)/2):n_pre+n_opt+n_adj,:]\n",
    "Y_res = Y[int((n_pre+n_opt+n_adj)/2):n_pre+n_opt+n_adj,:]\n",
    "x_res = X_res[:,0]\n",
    "y_res = Y_res[:,0]\n",
    "n_res = X_res.shape[0]\n",
    "\n",
    "X_test = X[n_pre+n_opt+n_adj:,:]\n",
    "Y_test = Y[n_pre+n_opt+n_adj:,:]\n",
    "x_test = X_test[:,0]\n",
    "y_test = Y_test[:,0]\n",
    "n_test = X_test.shape[0]\n",
    "\n",
    "# Estimate the mean using NN2\n",
    "est_type = \"NN2\"\n",
    "Y_res_pred, M_test = mean_est(est_type,X_lin,Y_lin,X_res,X_test)\n",
    "\n",
    "\n",
    "# Calculate the conformity scores\n",
    "y_res_pred = Y_res_pred[:,0]\n",
    "residuals = np.abs(y_res - y_res_pred)\n",
    "\n",
    "alpha = 0.05  # 95% confidence level\n",
    "k = int((1 - alpha) * len(y_lin))\n",
    "residuals_sorted = np.sort(residuals)\n",
    "threshold = residuals_sorted[k]\n",
    "\n",
    "# Calculate the prediction interval\n",
    "v_test = (threshold**2)*np.ones(len(m_test))\n",
    "V_test = v_test.reshape(-1,1)\n",
    "\n",
    "\n",
    "coverage = (np.power(Y_test[:,0]-M_test[:,0], 2) <= V_test[:,0]).mean()\n",
    "bandwidth = np.mean(V_test[:,0])\n",
    "print(\"The overall coverage is\", coverage)\n",
    "print(\"The mean bandwidth for testing data is\", bandwidth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a261c566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The overall coverage is 0.96\n",
      "The mean bandwidth for testing data is 65.81657723692204\n"
     ]
    }
   ],
   "source": [
    "# Test 4\n",
    "\n",
    "# Generate i.i.d data (Y follows a constrained Laplace)\n",
    "np.random.seed(1)\n",
    "n_pre = 1000\n",
    "n_opt = 500\n",
    "n_adj = 100\n",
    "n_t = 1000\n",
    "n = n_pre+n_opt+n_adj+n_t\n",
    "beta = np.array([1/math.sqrt(3),1/math.sqrt(3),-1/math.sqrt(3)])\n",
    "\n",
    "X = generate_points_on_sphere(n)\n",
    "\n",
    "# Specify the mean and standard deviation for Y\n",
    "mean_Y = np.power(X @ beta, 2)+5*np.power(X @ beta, 4)\n",
    "std_dev_Y = np.sqrt(1 + 25 * np.power(X @ beta, 4))\n",
    "mean_Y = mean_Y.reshape(-1,1)\n",
    "std_dev_Y  = std_dev_Y .reshape(-1,1)\n",
    "\n",
    "\n",
    "# Generate all Y values initially\n",
    "Y = np.random.laplace(mean_Y, std_dev_Y)\n",
    "\n",
    "    \n",
    "X_lin = X[0:int((n_pre+n_opt+n_adj)/2),:]\n",
    "Y_lin = Y[0:int((n_pre+n_opt+n_adj)/2),:]\n",
    "x_lin = X_lin[:,0]\n",
    "y_lin = Y_lin[:,0]\n",
    "n_lin = X_lin.shape[0]\n",
    "\n",
    "X_res = X[int((n_pre+n_opt+n_adj)/2):n_pre+n_opt+n_adj,:]\n",
    "Y_res = Y[int((n_pre+n_opt+n_adj)/2):n_pre+n_opt+n_adj,:]\n",
    "x_res = X_res[:,0]\n",
    "y_res = Y_res[:,0]\n",
    "n_res = X_res.shape[0]\n",
    "\n",
    "X_test = X[n_pre+n_opt+n_adj:,:]\n",
    "Y_test = Y[n_pre+n_opt+n_adj:,:]\n",
    "x_test = X_test[:,0]\n",
    "y_test = Y_test[:,0]\n",
    "n_test = X_test.shape[0]\n",
    "\n",
    "# Estimate the mean using NN2\n",
    "est_type = \"NN2\"\n",
    "Y_res_pred, M_test = mean_est(est_type,X_lin,Y_lin,X_res,X_test)\n",
    "\n",
    "\n",
    "# Calculate the conformity scores\n",
    "y_res_pred = Y_res_pred[:,0]\n",
    "residuals = np.abs(y_res - y_res_pred)\n",
    "\n",
    "alpha = 0.05  # 95% confidence level\n",
    "k = int((1 - alpha) * len(y_lin))\n",
    "residuals_sorted = np.sort(residuals)\n",
    "threshold = residuals_sorted[k]\n",
    "\n",
    "# Calculate the prediction interval\n",
    "v_test = (threshold**2)*np.ones(len(m_test))\n",
    "V_test = v_test.reshape(-1,1)\n",
    "\n",
    "\n",
    "coverage = (np.power(Y_test[:,0]-M_test[:,0], 2) <= V_test[:,0]).mean()\n",
    "bandwidth = np.mean(V_test[:,0])\n",
    "print(\"The overall coverage is\", coverage)\n",
    "print(\"The mean bandwidth for testing data is\", bandwidth)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
