{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c1180f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from All_functions_simulation_univariate import * \n",
    "from sklearn.linear_model import QuantileRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc16ddd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################### Data Generating ###################################\n",
    "\n",
    "def myData(i, n=2000):\n",
    "    \"\"\"\n",
    "    i: random seed\n",
    "    n: number of samples\n",
    "    \"\"\"\n",
    "    np.random.seed(i)\n",
    "    X = np.random.uniform(-1, 1, n).reshape(-1, 1)\n",
    "    Gamma_shape =5+np.power(X, 1)\n",
    "    Gamma_scale = 1+0.5*np.sin(X)\n",
    "    \n",
    "    Z1 = np.random.gamma(Gamma_shape, Gamma_scale)\n",
    "    Z2 = np.random.gamma(Gamma_shape, Gamma_scale)\n",
    "    Y= Z1-Z2\n",
    "    \n",
    "    upper_bound = np.sqrt(2*Gamma_shape)*Gamma_scale\n",
    "    lower_bound = -np.sqrt(2*Gamma_shape)*Gamma_scale\n",
    "    \n",
    "    # Correct values that fall out of bounds\n",
    "    while True:\n",
    "        out_of_bounds = (Y > upper_bound) | (Y < lower_bound)\n",
    "        if not np.any(out_of_bounds):\n",
    "            break\n",
    "        Z1[out_of_bounds] = np.random.gamma(Gamma_shape[out_of_bounds], Gamma_scale[out_of_bounds])\n",
    "        Z2[out_of_bounds] = np.random.gamma(Gamma_shape[out_of_bounds], Gamma_scale[out_of_bounds])\n",
    "        Y = Z1-Z2\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b19d15d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################### Different Methods ###################################\n",
    "\n",
    "def UTOPIA(X,Y,alpha = 0.05,n_train=950,n_adj=50, n_t = 1000,known_mean = \"False\"):\n",
    "    \"\"\"\n",
    "    X,Y: input data\n",
    "    alpha: coverage level\n",
    "    \"\"\"\n",
    "    X_pre = X[0:n_train,:].reshape(-1, 1)\n",
    "    Y_pre = Y[0:n_train,:].reshape(-1, 1)\n",
    "\n",
    "    X_opt = X[0:n_train,:].reshape(-1, 1)\n",
    "    Y_opt = Y[0:n_train,:].reshape(-1, 1)\n",
    "\n",
    "    X_adj = X[n_train:n_train+n_adj,:].reshape(-1, 1)\n",
    "    Y_adj = Y[n_train:n_train+n_adj,:].reshape(-1, 1)\n",
    "\n",
    "\n",
    "    X_t = X[n_train+n_adj:,:].reshape(-1, 1)\n",
    "    Y_t = Y[n_train+n_adj:,:].reshape(-1, 1)\n",
    "    \n",
    "    # Obtain mean estimator\n",
    "    if known_mean == \"True\":\n",
    "        M_pre = np.zeros(n_train).reshape(-1,1)\n",
    "        M_opt = np.zeros(n_train).reshape(-1,1)\n",
    "        M_adj = np.zeros(n_adj).reshape(-1,1)\n",
    "        M_t = np.zeros(n_t).reshape(-1,1)\n",
    "    else:\n",
    "        est_type = \"NN2\"\n",
    "        M_pre, M_opt, M_adj, M_t = mean_est(est_type,X_pre,Y_pre,X_opt,X_adj,X_t)\n",
    "        \n",
    "    # Obtain variance estimator\n",
    "    var_opt, var_adj, var_t = var_est(X_pre,Y_pre,M_pre, X_opt,X_adj,X_t,est_type =\"NN1\")\n",
    "    \n",
    "    # Obtain quantile estimators\n",
    "    quantile = [0.8,0.85,0.9,0.95]\n",
    "    m1,Q1_opt,Q1_adj,Q1_t = est_quantile(\"NN1\",quantile[0],X_pre,Y_pre,X_opt,X_adj,X_t)\n",
    "    m2,Q2_opt,Q2_adj,Q2_t = est_quantile(\"NN2\",quantile[1],X_pre,Y_pre,X_opt,X_adj,X_t)\n",
    "    m3,Q3_opt,Q3_adj,Q3_t = est_quantile(\"qrf\",quantile[2],X_pre,Y_pre,X_opt,X_adj,X_t)\n",
    "    m4,Q4_opt,Q4_adj,Q4_t = est_quantile(\"gb\",quantile[3],X_pre,Y_pre,X_opt,X_adj,X_t)\n",
    "    \n",
    "    # construct estimator matrix\n",
    "    E_opt = np.hstack(((Q1_opt-M_opt)**2, (Q2_opt-M_opt)**2, (Q3_opt-M_opt)**2, (Q4_opt-M_opt)**2, var_opt))\n",
    "    E_opt = E_opt.T\n",
    "    E_adj = np.hstack(((Q1_adj-M_adj)**2, (Q2_adj-M_adj)**2, (Q3_adj-M_adj)**2, (Q4_adj-M_adj)**2, var_adj))\n",
    "    E_adj = E_adj.T\n",
    "    E_t = np.hstack(((Q1_t-M_t)**2, (Q2_t-M_t)**2, (Q3_t-M_t)**2, (Q4_t-M_t)**2, var_t))\n",
    "    E_t = E_t.T\n",
    "    \n",
    "    # solve optimization problem\n",
    "    optimal_weight, V100_adj, V100_t = solve_opt(X_opt,Y_opt, M_opt, M_adj, M_t, X_adj, X_t, \"aug\", E_opt, E_adj, E_t)\n",
    "    \n",
    "    # adjust interval\n",
    "    alpha = 0.05\n",
    "    delta = interval_adj(X_adj,Y_adj,M_adj,V100_adj,alpha)\n",
    "    V_alpha_t = delta*V100_t\n",
    "    \n",
    "    # Output bandwidth and coverage\n",
    "    coverage = (np.power(Y_t[:,0]-M_t[:,0], 2) <= V_alpha_t[:,0]).mean()\n",
    "    bandwidth = np.mean(V_alpha_t[:,0])\n",
    "    \n",
    "    return coverage, bandwidth\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def LQR(X,Y,alpha = 0.05,n_train=1000,n_test = 1000, known_mean = \"False\"):\n",
    "    X_mean = X[0:n_train,:]\n",
    "    Y_mean = Y[0:n_train,:]\n",
    "    x_mean = X_mean[:,0]\n",
    "    y_mean = Y_mean[:,0]\n",
    "\n",
    "    X_quantile = X[0:n_train,:]\n",
    "    Y_quantile = Y[0:n_train,:]\n",
    "\n",
    "    X_test = X[n_train:,:]\n",
    "    Y_test = Y[n_train:,:]\n",
    "\n",
    "    # Estimate the mean\n",
    "    if known_mean == \"True\":\n",
    "        M_quantile = np.zeros(n_train).reshape(-1,1)\n",
    "        M_test = np.zeros(n_test).reshape(-1,1)\n",
    "    else:\n",
    "        est_type = \"NN2\"\n",
    "        M_quantile, M_test = mean_est_2(est_type,X_mean,Y_mean,X_quantile,X_test)\n",
    "        \n",
    "    # Estimate the quantile\n",
    "    model_quantile = QuantileRegressor(quantile=1-(alpha/2), alpha=0,solver='highs')\n",
    "    model_quantile.fit(X_quantile, (Y_quantile-M_quantile).reshape(-1))\n",
    "    Q_test = model_quantile.predict(X_test)\n",
    "    V_test = Q_test**2\n",
    "    V_test = V_test.reshape(-1,1)\n",
    "    \n",
    "    # Output bandwidth and coverage\n",
    "    coverage = (np.power(Y_test[:,0]-M_test[:,0], 2) <= V_test[:,0]).mean()\n",
    "    bandwidth = np.mean(V_test[:,0])\n",
    "    \n",
    "    return coverage, bandwidth\n",
    "\n",
    "\n",
    "def SplitCF(X,Y,alpha = 0.05,n_train=1000,n_test = 1000, known_mean = \"False\"):\n",
    "        X_mean = X[0:n_train,:]\n",
    "        Y_mean = Y[0:n_train,:]\n",
    "        x_mean = X_mean[:,0]\n",
    "        y_mean = Y_mean[:,0]\n",
    "\n",
    "        X_res = X[0:n_train,:]\n",
    "        Y_res = Y[0:n_train,:]\n",
    "        x_res = X_res[:,0]\n",
    "        y_res = Y_res[:,0]\n",
    "\n",
    "        X_test = X[n_train:,:]\n",
    "        Y_test = Y[n_train:,:]\n",
    "        x_test = X_test[:,0]\n",
    "        y_test = Y_test[:,0]\n",
    "        \n",
    "        # Estimate the mean\n",
    "        if known_mean == \"True\":\n",
    "            y_res_pred = np.zeros(n_train)\n",
    "            m_test = np.zeros(n_test)\n",
    "            M_test = m_test.reshape(-1,1)\n",
    "        else:\n",
    "            est_type = \"NN2\"\n",
    "            Y_res_pred, M_test = mean_est_2(est_type,X_mean,Y_mean,X_res,X_test)\n",
    "            y_res_pred = Y_res_pred[:,0]\n",
    "            \n",
    "        # Calculate the conformity scores\n",
    "        residuals = np.abs(y_res - y_res_pred)\n",
    "        k = int((1 - alpha) * n_train)\n",
    "        residuals_sorted = np.sort(residuals)\n",
    "        threshold = residuals_sorted[k]\n",
    "        \n",
    "        # Calculate the prediction interval\n",
    "        v_test = (threshold**2)*np.ones(n_test)\n",
    "        V_test = v_test.reshape(-1,1)\n",
    "        \n",
    "        # Output bandwidth and coverage\n",
    "        coverage = (np.power(Y_test[:,0]-M_test[:,0], 2) <= V_test[:,0]).mean()\n",
    "        bandwidth = np.mean(V_test[:,0])\n",
    "        \n",
    "        return coverage, bandwidth\n",
    "    \n",
    "\n",
    "    \n",
    "# Solve optimization problem in Liang's paper\n",
    "def sdpDual(K, Y):\n",
    "    n = Y.shape[0]\n",
    "    y = Y[:,0]\n",
    "    hB = cp.Variable((n, n), symmetric=True)\n",
    "    constraints = [hB >> 0]\n",
    "    constraints += [K[i, :] @ hB @ K[i, :] >= cp.square(y[i]) for i in range(n)]\n",
    "    prob = cp.Problem(cp.Minimize(cp.trace(K @ hB)), constraints)\n",
    "    prob.solve()\n",
    "    return hB.value\n",
    "    \n",
    "def SDP(X,Y,alpha = 0.05,n_train = 1000,n_opt = 100,n_t = 1000,known_mean = \"False\", sigma = 1):\n",
    "    \"\"\"\n",
    "    Liang's method with Gaussian kernel\n",
    "    sigma: parameter for the Gaussian kernel\n",
    "    \"\"\"\n",
    "    \n",
    "    X_pre = X[0:n_train,:].reshape(-1, 1)\n",
    "    Y_pre = Y[0:n_train,:].reshape(-1, 1)\n",
    "\n",
    "    X_opt = X[0:n_opt,:].reshape(-1, 1)\n",
    "    Y_opt = Y[0:n_opt,:].reshape(-1, 1)\n",
    "\n",
    "    X_adj = X[0:n_train,:].reshape(-1, 1)\n",
    "    Y_adj = Y[0:n_train,:].reshape(-1, 1)\n",
    "\n",
    "\n",
    "    X_t = X[n_train:,:].reshape(-1, 1)\n",
    "    Y_t = Y[n_train:,:].reshape(-1, 1)\n",
    "    \n",
    "    if known_mean == \"True\":\n",
    "        M_pre = np.zeros(n_train).reshape(-1,1)\n",
    "        M_opt = np.zeros(n_opt).reshape(-1,1)\n",
    "        M_adj = np.zeros(n_train).reshape(-1,1)\n",
    "        M_t = np.zeros(n_t).reshape(-1,1)\n",
    "    else:\n",
    "        est_type = \"NN2\"\n",
    "        M_pre, M_opt, M_adj, M_t = mean_est(est_type,X_pre,Y_pre,X_opt,X_adj,X_t)\n",
    "        \n",
    "    K_opt = rbf_kernel(X_opt, gamma = 1/(2*sigma**2))\n",
    "    output = sdpDual(K_opt, Y_opt-M_opt)\n",
    "        \n",
    "    K_adj = rbf_kernel(X_adj, X_opt, gamma = 1/(2*sigma**2))\n",
    "    shape_adj = K_adj @ output @ K_adj.T\n",
    "    shape_adj = shape_adj.diagonal()\n",
    "        \n",
    "    K_t = rbf_kernel(X_t, X_opt, gamma = 1/(2*sigma**2))\n",
    "    shape_t = K_t @ output @ K_t.T\n",
    "    shape_t = shape_t.diagonal()\n",
    "\n",
    "    delta = -1\n",
    "    Delta = 0\n",
    "    prop = 0.5\n",
    "    prop_outside = (np.power(Y_adj-M_adj, 2)[:,0] > (1 + delta) * shape_adj).mean()\n",
    "    while prop_outside > (0.75 * alpha) and delta != Delta:\n",
    "        delta = prop * delta + (1 - prop) * Delta\n",
    "        prop_outside = (np.power(Y_adj-M_adj, 2)[:,0] > (1 + delta) * shape_adj).mean()\n",
    "\n",
    "\n",
    "    V_alpha_t = (1 + delta) * shape_t\n",
    "    V_alpha_t = V_alpha_t.reshape(-1,1)\n",
    "\n",
    "    # Output bandwidth and coverage\n",
    "    coverage = (np.power(Y_t[:,0]-M_t[:,0], 2) <= V_alpha_t[:,0]).mean()\n",
    "    bandwidth = np.mean(V_alpha_t[:,0])\n",
    "    \n",
    "    return coverage, bandwidth\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0635834f",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################### Repeat Simulation ###################################\n",
    "\n",
    "times = 200\n",
    "\n",
    "UTOPIA_cover = np.zeros(times)\n",
    "UTOPIA_wide = np.zeros(times)\n",
    "\n",
    "LQR_cover = np.zeros(times)\n",
    "LQR_wide = np.zeros(times)\n",
    "\n",
    "SplitCF_cover = np.zeros(times)\n",
    "SplitCF_wide = np.zeros(times)\n",
    "\n",
    "SDP_cover = np.zeros(times)\n",
    "SDP_wide = np.zeros(times)\n",
    "\n",
    "\n",
    "for i in range(times):\n",
    "    X,Y = myData(i)\n",
    "    \n",
    "    UTOPIA_cover[i], UTOPIA_wide[i] = UTOPIA(X,Y,known_mean = \"False\")\n",
    "    LQR_cover[i], LQR_wide[i] = LQR(X,Y,known_mean = \"False\")\n",
    "    SplitCF_cover[i], SplitCF_wide[i] = SplitCF(X,Y,known_mean = \"False\")\n",
    "    SDP_cover[i], SDP_wide[i] = SDP(X,Y,known_mean = \"False\")\n",
    "    \n",
    "    \n",
    "\n",
    "Output = np.vstack((UTOPIA_cover,UTOPIA_wide,LQR_cover,LQR_wide,SplitCF_cover,SplitCF_wide,SDP_cover,SDP_wide))\n",
    "np.savetxt(\"repeat_S5_nosplit.csv\", Output, delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b821ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################### Results ###################################\n",
    "\n",
    "print(\"For UTOPIA:\")\n",
    "print(\"The mean of the coverage is\", np.mean(UTOPIA_cover))\n",
    "print(\"The median of the coverage is\", np.median(UTOPIA_cover))\n",
    "print(\"The SD of the coverage is\", np.std(UTOPIA_cover))\n",
    "print(\"The mean of the bandwidth is\", np.mean(UTOPIA_wide))\n",
    "print(\"The median of the bandwidth is\", np.median(UTOPIA_wide))\n",
    "print(\"The SD of the bandwidth is\", np.std(UTOPIA_wide))\n",
    "\n",
    "\n",
    "print(\"For LQR:\")\n",
    "print(\"The mean of the coverage is\", np.mean(LQR_cover))\n",
    "print(\"The median of the coverage is\", np.median(LQR_cover))\n",
    "print(\"The SD of the coverage is\", np.std(LQR_cover))\n",
    "print(\"The mean of the bandwidth is\", np.mean(LQR_wide))\n",
    "print(\"The median of the bandwidth is\", np.median(LQR_wide))\n",
    "print(\"The SD of the bandwidth is\", np.std(LQR_wide))\n",
    "\n",
    "print(\"For SplitCF:\")\n",
    "print(\"The mean of the coverage is\", np.mean(SplitCF_cover))\n",
    "print(\"The median of the coverage is\", np.median(SplitCF_cover))\n",
    "print(\"The SD of the coverage is\", np.std(SplitCF_cover))\n",
    "print(\"The mean of the bandwidth is\", np.mean(SplitCF_wide))\n",
    "print(\"The median of the bandwidth is\", np.median(SplitCF_wide))\n",
    "print(\"The SD of the bandwidth is\", np.std(SplitCF_wide))\n",
    "\n",
    "print(\"For SDP:\")\n",
    "print(\"The mean of the coverage is\", np.mean(SDP_cover))\n",
    "print(\"The median of the coverage is\", np.median(SDP_cover))\n",
    "print(\"The SD of the coverage is\", np.std(SDP_cover))\n",
    "print(\"The mean of the bandwidth is\", np.mean(SDP_wide))\n",
    "print(\"The median of the bandwidth is\", np.median(SDP_wide))\n",
    "print(\"The SD of the bandwidth is\", np.std(SDP_wide))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fd9dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################### Plots ###################################\n",
    "\n",
    "fig, axes = plt.subplots(1, 2,figsize=(12, 6))\n",
    "sns.histplot(UTOPIA_cover.reshape(-1, 1), kde = True,ax=axes[0],legend=False)\n",
    "axes[0].set_title('Histogram of coverage for UTOPIA')\n",
    "sns.histplot(UTOPIA_wide.reshape(-1, 1), kde = True,ax=axes[1],legend=False)\n",
    "axes[1].set_title('Histogram of bandwidth for UTOPIA')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd0f53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################### Plots ###################################\n",
    "\n",
    "fig, axes = plt.subplots(1, 2,figsize=(12, 6))\n",
    "sns.histplot(LQR_cover.reshape(-1, 1), kde = True,ax=axes[0],legend=False)\n",
    "axes[0].set_title('Histogram of coverage for LQR')\n",
    "sns.histplot(LQR_wide.reshape(-1, 1), kde = True,ax=axes[1],legend=False)\n",
    "axes[1].set_title('Histogram of bandwidth for LQR')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61433669",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################### Plots ###################################\n",
    "\n",
    "fig, axes = plt.subplots(1, 2,figsize=(12, 6))\n",
    "sns.histplot(SplitCF_cover.reshape(-1, 1), kde = True,ax=axes[0],legend=False)\n",
    "axes[0].set_title('Histogram of coverage for SplitCF')\n",
    "sns.histplot(SplitCF_wide.reshape(-1, 1), kde = True,ax=axes[1],legend=False)\n",
    "axes[1].set_title('Histogram of bandwidth for SplitCF')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8237aafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################### Plots ###################################\n",
    "\n",
    "fig, axes = plt.subplots(1, 2,figsize=(12, 6))\n",
    "sns.histplot(SDP_cover.reshape(-1, 1), kde = True,ax=axes[0],legend=False)\n",
    "axes[0].set_title('Histogram of coverage for SDP')\n",
    "sns.histplot(SDP_wide.reshape(-1, 1), kde = True,ax=axes[1],legend=False)\n",
    "axes[1].set_title('Histogram of bandwidth for SDP')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-env [~/.conda/envs/torch-env/]",
   "language": "python",
   "name": "conda_torch-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
